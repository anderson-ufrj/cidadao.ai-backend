# üö® CORRE√á√ÉO URGENTE - Investiga√ß√µes Travadas com Maritaca AI

## Problema Identificado
As investiga√ß√µes est√£o travando em 30% porque:
1. O sistema est√° configurado para usar **Groq** por padr√£o (`llm_provider: "groq"`)
2. Voc√™s querem usar **Maritaca AI** (modelo brasileiro)
3. A configura√ß√£o n√£o est√° apontando para Maritaca

## Solu√ß√£o Imediata no Railway (5 minutos)

### 1Ô∏è‚É£ Configurar Maritaca no Railway

Acesse o Railway Dashboard ‚Üí Servi√ßo `cidadao-api-production` ‚Üí **Variables** e adicione/verifique:

```env
# Configurar Maritaca como provider principal
LLM_PROVIDER=maritaca

# API Key da Maritaca (obter em https://chat.maritaca.ai)
MARITACA_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx

# Modelo da Maritaca (use sabiazinho-3 que √© mais barato)
LLM_MODEL_NAME=sabiazinho-3
```

### 2Ô∏è‚É£ Remover/Comentar GROQ se existir

Se houver `GROQ_API_KEY` configurada, voc√™ pode:
- Remov√™-la completamente
- Ou mant√™-la como backup

### 3Ô∏è‚É£ Vari√°veis Completas Recomendadas

```env
# LLM Principal - Maritaca AI
LLM_PROVIDER=maritaca
MARITACA_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx
LLM_MODEL_NAME=sabiazinho-3
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2048

# Banco de Dados (j√° deve estar configurado)
DATABASE_URL=${{Postgres.DATABASE_URL}}

# Seguran√ßa (j√° devem estar configurados)
JWT_SECRET_KEY=xxxxx
SECRET_KEY=xxxxx
```

### 4Ô∏è‚É£ Reiniciar o Servi√ßo

Ap√≥s adicionar as vari√°veis:
1. No Railway, clique em **Deployments**
2. O servi√ßo reiniciar√° automaticamente ao detectar mudan√ßas nas vari√°veis
3. Aguarde 1-2 minutos para o novo deploy

## Como Obter a API Key da Maritaca

1. Acesse: https://chat.maritaca.ai
2. Fa√ßa login ou crie uma conta
3. V√° em **Configura√ß√µes** ‚Üí **API Keys**
4. Crie uma nova chave
5. Copie e adicione no Railway como `MARITACA_API_KEY`

## Teste R√°pido Ap√≥s Configura√ß√£o

```bash
# Criar investiga√ß√£o
curl -X POST https://cidadao-api-production.up.railway.app/api/v1/investigations/start \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Teste com Maritaca AI",
    "data_source": "contracts",
    "filters": {"ano": 2024},
    "anomaly_types": ["price"]
  }'

# Resposta esperada:
# {"investigation_id": "xxx", "status": "started", "message": "Investigation queued"}

# Aguarde 15-30 segundos e verifique o status
curl https://cidadao-api-production.up.railway.app/api/v1/investigations/{ID}/status
```

## Verifica√ß√£o nos Logs do Railway

Ap√≥s reiniciar, procure nos logs por:

‚úÖ **Sucesso**:
```
maritaca_client_initialized
LLM provider: maritaca
Investigation completed successfully
Progress: 100%
```

‚ùå **Problemas**:
```
MARITACA_API_KEY not found
Failed to initialize Maritaca
LLM timeout
```

## Modelos Dispon√≠veis da Maritaca

- `sabiazinho-3` - Mais barato e eficiente ‚úÖ (Recomendado)
- `sabia-3` - Modelo padr√£o
- `sabia-3-medium` - Mais capacidade
- `sabia-3-large` - M√°xima capacidade

## Ajuste Fino para Maritaca

Se quiser otimizar ainda mais, adicione:

```env
# Configura√ß√µes espec√≠ficas para Maritaca
LLM_TEMPERATURE=0.5  # Mais determin√≠stico para an√°lises
LLM_MAX_TOKENS=3000  # Maritaca suporta at√© 8192
LLM_TOP_P=0.95       # Melhor para portugu√™s
```

## Fallback Manual (Tempor√°rio)

Se ainda n√£o tiver a API key da Maritaca, voc√™ pode temporariamente usar um mock:

```env
LLM_PROVIDER=mock
# Isso far√° o sistema usar respostas simuladas (n√£o recomendado para produ√ß√£o)
```

## Corre√ß√£o no C√≥digo (Pr√≥ximo Deploy)

Para garantir que Maritaca seja usado corretamente, precisamos:

1. Adicionar Maritaca como provider oficial no `llm/providers.py`
2. Configurar fallback autom√°tico
3. Adicionar retry com backoff espec√≠fico para Maritaca

## Status Esperado Ap√≥s Corre√ß√£o

- ‚úÖ Investiga√ß√µes completam em 20-40 segundos
- ‚úÖ Progresso: 0% ‚Üí 30% ‚Üí 70% ‚Üí 100%
- ‚úÖ Mensagens em portugu√™s nativo
- ‚úÖ Melhor compreens√£o de termos brasileiros
- ‚úÖ Dados salvos no PostgreSQL

## Troubleshooting

### Se continuar travando em 30%:
1. Verifique se `LLM_PROVIDER=maritaca` est√° configurado
2. Confirme que a API key √© v√°lida
3. Teste a API key localmente:

```python
import httpx

headers = {
    "Authorization": f"Bearer {SUA_API_KEY}",
    "Content-Type": "application/json"
}

response = httpx.post(
    "https://chat.maritaca.ai/api/chat/completions",
    headers=headers,
    json={
        "model": "sabiazinho-3",
        "messages": [{"role": "user", "content": "Ol√°"}]
    }
)
print(response.status_code)  # Deve ser 200
```

### Rate Limits da Maritaca:
- Verifique os limites da sua conta
- Use `sabiazinho-3` que √© mais econ√¥mico
- Implemente cache para queries repetidas

## Contato e Suporte

- Maritaca AI: https://chat.maritaca.ai/docs
- Railway: Verifique os logs em tempo real
- Alternativa: Configure GROQ_API_KEY como fallback
