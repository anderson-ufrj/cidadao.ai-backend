# ğŸ“Š Guia Completo de Dashboards Grafana - CidadÃ£o.AI

**Autor**: Anderson Henrique da Silva
**LocalizaÃ§Ã£o**: Minas Gerais, Brasil
**Data**: 2025-10-30
**VersÃ£o**: 1.0
**Status**: DocumentaÃ§Ã£o de Monitoramento

---

## ğŸ¯ VisÃ£o Geral

Este documento descreve a configuraÃ§Ã£o completa de monitoramento do backend CidadÃ£o.AI usando **Grafana + Prometheus**, incluindo todos os dashboards, mÃ©tricas disponÃ­veis e como utilizÃ¡-los para monitorar a saÃºde do sistema em produÃ§Ã£o.

### InformaÃ§Ãµes de ProduÃ§Ã£o
- **URL**: https://cidadao-api-production.up.railway.app
- **Uptime**: 99.9% desde 07/10/2025
- **Stack**: FastAPI + PostgreSQL + Redis + Celery
- **Monitoramento**: Prometheus + Grafana
- **LocalizaÃ§Ã£o**: Railway (us-west)

---

## ğŸ“ Estrutura de Arquivos

```
monitoring/
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/                    # Dashboards JSON
â”‚   â”‚   â”œâ”€â”€ cidadao-ai-overview.json           # â­ Dashboard principal
â”‚   â”‚   â”œâ”€â”€ cidadao-ai-agents.json             # Monitoramento de agentes
â”‚   â”‚   â”œâ”€â”€ federal-apis-dashboard.json        # APIs federais
â”‚   â”‚   â”œâ”€â”€ slo-sla-dashboard.json             # SLA/SLO tracking
â”‚   â”‚   â”œâ”€â”€ system-performance.json            # Performance do sistema
â”‚   â”‚   â””â”€â”€ zumbi-agent-dashboard.json         # Agente Zumbi especÃ­fico
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â””â”€â”€ dashboards.yml         # Auto-provisioning
â”‚   â”‚   â””â”€â”€ datasources/
â”‚   â”‚       â””â”€â”€ prometheus.yml         # Datasource config
â”‚   â””â”€â”€ grafana.ini                    # ConfiguraÃ§Ã£o do Grafana
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml                 # ConfiguraÃ§Ã£o do Prometheus
â””â”€â”€ docker-compose.monitoring.yml      # Stack completo
```

---

## ğŸš€ Quick Start

### Iniciar Stack de Monitoramento

```bash
# 1. Subir Prometheus + Grafana
docker-compose -f docker-compose.monitoring.yml up -d

# 2. Acessar Grafana
# URL: http://localhost:3000
# Login: admin / cidadao123

# 3. Verificar Prometheus
# URL: http://localhost:9090
# Targets: http://localhost:9090/targets
```

### Verificar MÃ©tricas do Backend

```bash
# Endpoint de mÃ©tricas Prometheus
curl http://localhost:8000/health/metrics

# Exemplo de saÃ­da:
# cidadao_ai_agent_tasks_total{agent_name="zumbi",status="success"} 142.0
# cidadao_ai_investigations_total{status="completed"} 37.0
```

---

## ğŸ“Š Dashboards DisponÃ­veis

### 1. **Overview - Dashboard Principal** â­

**Arquivo**: `cidadao-ai-overview.json`
**PropÃ³sito**: VisÃ£o geral de saÃºde e performance do sistema
**AtualizaÃ§Ã£o**: Tempo real (5 segundos)

#### PainÃ©is Principais:

**Linha 1: MÃ©tricas de SaÃºde**
- ğŸŸ¢ **Uptime** - Porcentagem de disponibilidade (Meta: 99.9%)
- ğŸ“Š **Requests/sec** - Taxa de requisiÃ§Ãµes (tempo real)
- âš ï¸ **Error Rate** - Porcentagem de erros (Meta: <1%)
- â±ï¸ **Response Time (p95)** - Tempo de resposta 95Âº percentil (Meta: <200ms)

**Linha 2: Atividade de InvestigaÃ§Ãµes**
- ğŸ“ˆ **InvestigaÃ§Ãµes Ativas** - NÃºmero de investigaÃ§Ãµes em andamento
- âœ… **Taxa de ConclusÃ£o** - Porcentagem de investigaÃ§Ãµes completadas
- â° **Tempo MÃ©dio** - Tempo mÃ©dio de processamento
- ğŸ‘¥ **UsuÃ¡rios Ativos** - NÃºmero de usuÃ¡rios simultÃ¢neos

**Linha 3: Agentes Multi-Agent**
- ğŸ¤– **Agentes Ativos** - NÃºmero de agentes processando tarefas
- ğŸ“Š **Tarefas/min** - Taxa de execuÃ§Ã£o de tarefas
- âœ… **Taxa de Sucesso** - Porcentagem de tarefas bem-sucedidas
- âš¡ **Performance** - Tempo mÃ©dio de execuÃ§Ã£o

**Linha 4: Infraestrutura**
- ğŸ’¾ **PostgreSQL** - ConexÃµes ativas, query time, locks
- ğŸ”´ **Redis** - Hit rate, memÃ³ria usada, evictions
- ğŸ“® **Celery** - Workers ativos, fila, tarefas falhadas
- ğŸ–¥ï¸ **Sistema** - CPU, memÃ³ria (se disponÃ­vel)

#### Queries PromQL Importantes:

```promql
# Uptime (Ãºltimas 24h)
avg_over_time(up{job="cidadao-ai-backend"}[24h]) * 100

# Requests por segundo
rate(http_requests_total[5m])

# Error rate
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100

# Response time p95
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# InvestigaÃ§Ãµes ativas
cidadao_ai_investigations_total{status="in_progress"}

# Taxa de sucesso de agentes
rate(cidadao_ai_agent_tasks_total{status="success"}[5m]) /
rate(cidadao_ai_agent_tasks_total[5m]) * 100
```

---

### 2. **Agents Performance - Monitoramento de Agentes** ğŸ¤–

**Arquivo**: `cidadao-ai-agents.json`
**PropÃ³sito**: Monitorar performance de todos os 16 agentes
**AtualizaÃ§Ã£o**: 10 segundos

#### PainÃ©is por Agente:

Para cada um dos 16 agentes (Zumbi, Anita, Tiradentes, etc.):

**MÃ©tricas Individuais**:
- ğŸ“Š **Tarefas Executadas** - Total por tipo de tarefa
- â±ï¸ **Tempo de ExecuÃ§Ã£o** - DistribuiÃ§Ã£o de latÃªncia (p50, p95, p99)
- âœ… **Taxa de Sucesso** - % de tarefas bem-sucedidas
- ğŸ”„ **Tarefas Concorrentes** - NÃºmero de tarefas simultÃ¢neas
- ğŸ“ˆ **Throughput** - Tarefas por minuto
- âš ï¸ **Erros** - Taxa de erro e tipos de falha

**VisualizaÃ§Ãµes**:
- Time series para tendÃªncias
- Heatmap para distribuiÃ§Ã£o de latÃªncia
- Tabela com detalhes de falhas
- Gauge para taxa de sucesso

#### Queries por Agente:

```promql
# Total de tarefas do Zumbi
sum(cidadao_ai_agent_tasks_total{agent_name="zumbi"})

# Tempo mÃ©dio de execuÃ§Ã£o
rate(cidadao_ai_agent_task_duration_seconds_sum{agent_name="zumbi"}[5m]) /
rate(cidadao_ai_agent_task_duration_seconds_count{agent_name="zumbi"}[5m])

# Taxa de sucesso
rate(cidadao_ai_agent_tasks_total{agent_name="zumbi",status="success"}[5m]) /
rate(cidadao_ai_agent_tasks_total{agent_name="zumbi"}[5m]) * 100

# p95 latency
histogram_quantile(0.95,
  rate(cidadao_ai_agent_task_duration_seconds_bucket{agent_name="zumbi"}[5m])
)
```

**Alertas Configurados**:
- âš ï¸ Taxa de erro > 5% (Warning)
- ğŸš¨ Taxa de erro > 10% (Critical)
- âš ï¸ p95 latency > 5s (Warning)
- ğŸš¨ p95 latency > 10s (Critical)

---

### 3. **Federal APIs - Monitoramento de APIs Externas** ğŸŒ

**Arquivo**: `federal-apis-dashboard.json`
**PropÃ³sito**: Monitorar integraÃ§Ãµes com APIs governamentais (30+ APIs)
**AtualizaÃ§Ã£o**: 30 segundos

#### APIs Monitoradas:

**APIs Federais** (7):
1. IBGE - Geografia e estatÃ­sticas
2. DataSUS - Dados de saÃºde
3. INEP - EducaÃ§Ã£o
4. PNCP - Contratos pÃºblicos
5. Compras.gov.br - Compras governamentais
6. Minha Receita - Receita federal
7. BCB - Banco Central

**Portal da TransparÃªncia**:
- Contratos
- Despesas
- ConvÃªnios
- LicitaÃ§Ãµes
- Servidores

**APIs Estaduais** (11):
- TCEs: 6 tribunais (SP, RJ, MG, BA, PE, CE)
- CKAN: 5 portais (SP, RJ, RS, SC, BA)

#### MÃ©tricas por API:

- ğŸ“Š **Request Rate** - RequisiÃ§Ãµes por minuto
- â±ï¸ **Response Time** - LatÃªncia (p50, p95, p99)
- âœ… **Success Rate** - Taxa de sucesso (2xx responses)
- âš ï¸ **Error Rate** - Erros 4xx e 5xx
- ğŸš¦ **Rate Limit Status** - Uso de quota
- ğŸ“ˆ **Availability** - Uptime da API externa

#### Queries para APIs:

```promql
# Request rate por API
rate(external_api_requests_total{api_name="ibge"}[5m])

# Response time mÃ©dio
rate(external_api_duration_seconds_sum{api_name="ibge"}[5m]) /
rate(external_api_duration_seconds_count{api_name="ibge"}[5m])

# Taxa de erro
rate(external_api_requests_total{api_name="ibge",status=~"5.."}[5m]) /
rate(external_api_requests_total{api_name="ibge"}[5m]) * 100

# Disponibilidade (Ãºltimas 24h)
avg_over_time(up{job="external-api",api="ibge"}[24h]) * 100
```

**Alertas de APIs**:
- âš ï¸ Error rate > 10% (Warning)
- ğŸš¨ Error rate > 25% (Critical)
- âš ï¸ Response time > 2s (Warning)
- ğŸš¨ Availability < 95% (Critical)

---

### 4. **SLO/SLA Tracking - Acordos de NÃ­vel de ServiÃ§o** ğŸ“‹

**Arquivo**: `slo-sla-dashboard.json`
**PropÃ³sito**: Monitorar cumprimento de SLAs e SLOs
**AtualizaÃ§Ã£o**: 1 minuto

#### SLAs Definidos:

**Disponibilidade**:
- âœ… **Target**: 99.9% uptime mensal
- ğŸ“Š **Atual**: Calculado em tempo real
- â° **Downtime Permitido**: 43.2 minutos/mÃªs

**Performance**:
- âœ… **API Response (p95)**: < 200ms
- âœ… **Chat Response (p95)**: < 500ms
- âœ… **Investigation (p95)**: < 2s
- âœ… **Report Generation (p95)**: < 5s

**Qualidade**:
- âœ… **Error Rate**: < 1%
- âœ… **Agent Success Rate**: > 95%
- âœ… **Data Freshness**: < 1 hora

#### SLOs (Service Level Objectives):

**Tier 1 (Critical)**:
- Uptime: 99.95%
- P95 latency: < 150ms
- Error rate: < 0.5%

**Tier 2 (Important)**:
- Uptime: 99.9%
- P95 latency: < 200ms
- Error rate: < 1%

**Tier 3 (Standard)**:
- Uptime: 99.5%
- P95 latency: < 500ms
- Error rate: < 2%

#### Error Budget Tracking:

```promql
# Error budget mensal (99.9% SLA)
# Permitido: 0.1% de erros = 43.2 min downtime
1 - (
  sum(rate(http_requests_total{status=~"5.."}[30d])) /
  sum(rate(http_requests_total[30d]))
) * 100

# Budget consumido (%)
(1 - (uptime_atual / 99.9)) * 100

# Tempo atÃ© esgotar budget
error_budget_remaining / current_error_rate
```

**Alertas de SLA**:
- âš ï¸ Uptime < 99.9% (SLA breach iminente)
- ğŸš¨ Uptime < 99.5% (SLA breach)
- âš ï¸ Error budget < 20% (AtenÃ§Ã£o)
- ğŸš¨ Error budget < 10% (CrÃ­tico)

---

### 5. **System Performance - Performance Detalhada** âš¡

**Arquivo**: `system-performance.json`
**PropÃ³sito**: AnÃ¡lise profunda de performance e bottlenecks
**AtualizaÃ§Ã£o**: 5 segundos

#### Categorias de AnÃ¡lise:

**1. HTTP Performance**:
- ğŸ“Š Latency distribution (heatmap)
- ğŸ“ˆ Request rate por endpoint
- ğŸ” Slow endpoints (p99 > 1s)
- ğŸ“Š Response size distribution

**2. Database Performance**:
- ğŸ” Query time distribution
- ğŸ“Š ConexÃµes ativas vs idle
- âš ï¸ Long-running queries (> 1s)
- ğŸ”’ Lock contention
- ğŸ’¾ Cache hit rate

**3. Redis Performance**:
- ğŸ“Š Hit rate (target: > 90%)
- ğŸ’¾ Memory usage
- ğŸ”„ Evictions rate
- â±ï¸ Command latency
- ğŸ“ˆ Keys per database

**4. Celery Workers**:
- ğŸ”„ Active tasks
- ğŸ“® Queue depth
- â±ï¸ Task processing time
- âš ï¸ Failed tasks
- ğŸ“Š Worker utilization

**5. Resource Usage** (se disponÃ­vel):
- ğŸ–¥ï¸ CPU utilization
- ğŸ’¾ Memory usage
- ğŸ“Š Disk I/O
- ğŸŒ Network throughput

#### Queries de Performance:

```promql
# Top 10 endpoints mais lentos (p95)
topk(10,
  histogram_quantile(0.95,
    rate(http_request_duration_seconds_bucket[5m])
  )
)

# Database: queries lentas
rate(postgresql_slow_queries_total[5m])

# Redis: hit rate
rate(redis_keyspace_hits_total[5m]) /
(rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m])) * 100

# Celery: tempo mÃ©dio de processamento
rate(celery_task_duration_seconds_sum[5m]) /
rate(celery_task_duration_seconds_count[5m])
```

---

### 6. **Zumbi Agent - Dashboard Especializado** ğŸ”

**Arquivo**: `zumbi-agent-dashboard.json`
**PropÃ³sito**: Monitoramento detalhado do agente de detecÃ§Ã£o de anomalias
**AtualizaÃ§Ã£o**: 5 segundos

#### MÃ©tricas EspecÃ­ficas do Zumbi:

**DetecÃ§Ã£o de Anomalias**:
- ğŸ” **Anomalias Detectadas** - Total por tipo
- ğŸ“Š **Confidence Score** - DistribuiÃ§Ã£o de confianÃ§a
- âš ï¸ **Severity Distribution** - Low, Medium, High, Critical
- ğŸ“ˆ **Detection Rate** - Anomalias por hora

**Performance de AnÃ¡lise**:
- â±ï¸ **FFT Analysis Time** - Tempo de anÃ¡lise espectral
- ğŸ“Š **Statistical Analysis** - Tempo de anÃ¡lise estatÃ­stica
- ğŸ”„ **Concurrent Analyses** - AnÃ¡lises simultÃ¢neas
- âœ… **Success Rate** - Taxa de anÃ¡lises bem-sucedidas

**Tipos de Anomalias Monitoradas**:
1. **Price Deviation** - Desvio de preÃ§o (> 2.5Ïƒ)
2. **Supplier Concentration** - ConcentraÃ§Ã£o > 70%
3. **Contract Similarity** - Similaridade > 85%
4. **Temporal Patterns** - PadrÃµes sazonais anormais
5. **Spectral Anomalies** - FFT outliers

#### Queries do Zumbi:

```promql
# Total de anomalias por tipo
sum by (anomaly_type) (
  cidadao_ai_anomalies_detected_total{agent_name="zumbi"}
)

# MÃ©dia de confidence score
avg(cidadao_ai_anomaly_confidence_score{agent_name="zumbi"})

# Taxa de detecÃ§Ã£o (anomalias/hora)
rate(cidadao_ai_anomalies_detected_total{agent_name="zumbi"}[1h]) * 3600

# Anomalias crÃ­ticas (Ãºltimas 24h)
increase(
  cidadao_ai_anomalies_detected_total{
    agent_name="zumbi",
    severity="critical"
  }[24h]
)
```

---

## ğŸ”” ConfiguraÃ§Ã£o de Alertas

### Alertas CrÃ­ticos (PagerDuty/Slack)

```yaml
# monitoring/prometheus/alerts/critical.yml
groups:
  - name: critical_alerts
    interval: 1m
    rules:
      # Sistema Down
      - alert: SystemDown
        expr: up{job="cidadao-ai-backend"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Sistema CidadÃ£o.AI OFFLINE"
          description: "Backend nÃ£o estÃ¡ respondendo hÃ¡ {{ $value }} minuto(s)"

      # SLA Breach
      - alert: SLABreach
        expr: |
          (1 - avg_over_time(up{job="cidadao-ai-backend"}[30d])) * 100 > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "SLA 99.9% violado"
          description: "Uptime atual: {{ $value }}%"

      # High Error Rate
      - alert: HighErrorRate
        expr: |
          rate(http_requests_total{status=~"5.."}[5m]) /
          rate(http_requests_total[5m]) * 100 > 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Taxa de erro acima de 5%"
          description: "Error rate: {{ $value }}%"

      # Database Down
      - alert: DatabaseDown
        expr: postgresql_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL OFFLINE"

      # Redis Down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis OFFLINE"
```

### Alertas de Warning (Email/Slack)

```yaml
  - name: warning_alerts
    interval: 5m
    rules:
      # Slow Response Time
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95,
            rate(http_request_duration_seconds_bucket[5m])
          ) > 0.2
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Response time p95 > 200ms"
          description: "LatÃªncia: {{ $value }}s"

      # Agent High Error Rate
      - alert: AgentHighErrors
        expr: |
          rate(cidadao_ai_agent_tasks_total{status="error"}[5m]) /
          rate(cidadao_ai_agent_tasks_total[5m]) * 100 > 10
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Agente {{ $labels.agent_name }} com > 10% erros"

      # Low Redis Hit Rate
      - alert: LowCacheHitRate
        expr: |
          rate(redis_keyspace_hits_total[5m]) /
          (rate(redis_keyspace_hits_total[5m]) +
           rate(redis_keyspace_misses_total[5m])) * 100 < 70
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Redis hit rate < 70%"
          description: "Hit rate: {{ $value }}%"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes /
                node_memory_MemTotal_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "MemÃ³ria > 85% utilizada"
```

---

## ğŸ“– Como Usar os Dashboards

### 1. Monitoramento DiÃ¡rio (Dashboard Overview)

**Rotina Matinal** (5 minutos):
1. Abrir dashboard Overview
2. Verificar uptime (deve estar verde, > 99.9%)
3. Checar error rate (deve estar < 1%)
4. Verificar response time (p95 < 200ms)
5. Revisar investigaÃ§Ãµes (throughput normal)

**Indicadores de SaÃºde**:
- ğŸŸ¢ Verde: Tudo OK
- ğŸŸ¡ Amarelo: AtenÃ§Ã£o necessÃ¡ria
- ğŸ”´ Vermelho: AÃ§Ã£o imediata

### 2. InvestigaÃ§Ã£o de Performance (System Performance)

**Quando usar**:
- Response time aumentou
- UsuÃ¡rios reportam lentidÃ£o
- Error rate subiu

**Processo**:
1. Verificar heatmap de latÃªncia
2. Identificar endpoints lentos (top 10)
3. Checar database: queries lentas, locks
4. Verificar Redis: hit rate, memory
5. Analisar Celery: queue depth, failed tasks

### 3. Debug de Anomalias (Zumbi Dashboard)

**Quando usar**:
- Investigar anomalias especÃ­ficas
- Validar detecÃ§Ã£o
- Ajustar thresholds

**AnÃ¡lise**:
1. Ver tipos de anomalias detectadas
2. Analisar confidence scores
3. Verificar severity distribution
4. Identificar padrÃµes temporais
5. Validar com dados reais

### 4. Monitoramento de Agentes (Agents Performance)

**Quando usar**:
- Verificar saÃºde de agentes especÃ­ficos
- Investigar falhas
- Otimizar performance

**Checklist por Agente**:
- [ ] Taxa de sucesso > 95%
- [ ] p95 latency dentro do esperado
- [ ] Sem erros recorrentes
- [ ] Throughput consistente

### 5. Rastreamento de SLA (SLO/SLA Dashboard)

**Uso Executivo**:
- RelatÃ³rios mensais de SLA
- Planejamento de capacity
- ComunicaÃ§Ã£o com stakeholders

**MÃ©tricas Chave**:
- Uptime mensal
- Error budget consumido
- TendÃªncias de performance
- Compliance com SLOs

---

## ğŸ¨ PersonalizaÃ§Ã£o de Dashboards

### Adicionar Novo Painel

1. **No Grafana UI**:
   - Clicar em "Add panel"
   - Selecionar visualizaÃ§Ã£o
   - Configurar query PromQL
   - Ajustar opÃ§Ãµes visuais
   - Salvar

2. **Exportar JSON**:
   - Dashboard settings â†’ JSON Model
   - Copiar JSON
   - Salvar em `monitoring/grafana/dashboards/`

3. **Versionar no Git**:
   ```bash
   git add monitoring/grafana/dashboards/
   git commit -m "feat(monitoring): add new dashboard panel"
   ```

### Criar VariÃ¡veis de Dashboard

```json
{
  "templating": {
    "list": [
      {
        "name": "agent",
        "type": "query",
        "query": "label_values(cidadao_ai_agent_tasks_total, agent_name)",
        "multi": true,
        "includeAll": true
      },
      {
        "name": "interval",
        "type": "interval",
        "query": "5m,15m,1h,6h,24h",
        "current": {
          "text": "5m",
          "value": "5m"
        }
      }
    ]
  }
}
```

### Adicionar AnotaÃ§Ãµes

```json
{
  "annotations": {
    "list": [
      {
        "name": "Deployments",
        "datasource": "Prometheus",
        "expr": "changes(process_start_time_seconds[5m]) > 0",
        "tagKeys": "version",
        "textFormat": "Deploy {{ version }}"
      }
    ]
  }
}
```

---

## ğŸ”§ Troubleshooting

### Dashboard NÃ£o Carrega

**Problema**: Dashboard vazio ou erro de carregamento

**SoluÃ§Ã£o**:
```bash
# 1. Verificar Prometheus estÃ¡ coletando mÃ©tricas
curl http://localhost:9090/api/v1/query?query=up

# 2. Verificar datasource no Grafana
# Grafana â†’ Configuration â†’ Data Sources â†’ Prometheus
# Test: Should return "Data source is working"

# 3. Reiniciar Grafana
docker-compose -f docker-compose.monitoring.yml restart grafana
```

### MÃ©tricas NÃ£o Aparecem

**Problema**: Query retorna "No data"

**SoluÃ§Ã£o**:
```bash
# 1. Verificar backend estÃ¡ expondo mÃ©tricas
curl http://localhost:8000/health/metrics | grep cidadao_ai

# 2. Verificar Prometheus estÃ¡ scraping
# http://localhost:9090/targets
# cidadao-ai-backend deve estar "UP"

# 3. Testar query no Prometheus UI
# http://localhost:9090/graph
# Executar query manualmente
```

### Alertas NÃ£o Disparam

**Problema**: Alertas configurados mas nÃ£o notificam

**SoluÃ§Ã£o**:
```bash
# 1. Verificar regras de alerta
curl http://localhost:9090/api/v1/rules

# 2. Verificar Alertmanager
docker-compose logs alertmanager

# 3. Testar notificaÃ§Ã£o manualmente
# Prometheus â†’ Alerts â†’ Fire test alert
```

---

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Oficial
- **Grafana**: https://grafana.com/docs/
- **Prometheus**: https://prometheus.io/docs/
- **PromQL**: https://prometheus.io/docs/prometheus/latest/querying/basics/

### Exemplos de Queries PromQL

```promql
# Taxa de requisiÃ§Ãµes (req/s)
rate(http_requests_total[5m])

# LatÃªncia p95 por endpoint
histogram_quantile(0.95,
  sum by (le, path) (
    rate(http_request_duration_seconds_bucket[5m])
  )
)

# Top 5 endpoints por volume
topk(5, sum by (path) (rate(http_requests_total[5m])))

# Error rate por status code
sum by (status) (rate(http_requests_total{status=~"5.."}[5m]))

# Throughput de agentes
sum(rate(cidadao_ai_agent_tasks_total[5m])) by (agent_name)

# Anomalias por severidade (Ãºltimas 24h)
increase(cidadao_ai_anomalies_detected_total[24h]) by (severity)
```

### IntegraÃ§Ã£o com Alertas

```yaml
# alertmanager.yml
receivers:
  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/XXX'
        channel: '#ops-alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ .CommonAnnotations.description }}'

  - name: 'pagerduty'
    pagerduty_configs:
      - service_key: 'XXX'
        description: '{{ .CommonAnnotations.summary }}'

route:
  receiver: 'slack'
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 5m
  repeat_interval: 4h

  routes:
    - match:
        severity: critical
      receiver: pagerduty
```

---

## âœ… Checklist de ImplementaÃ§Ã£o

### ConfiguraÃ§Ã£o Inicial

- [ ] Docker Compose configurado
- [ ] Prometheus coletando mÃ©tricas (/health/metrics)
- [ ] Grafana acessÃ­vel (http://localhost:3000)
- [ ] Datasource Prometheus configurado
- [ ] Dashboards importados

### Dashboards Funcionais

- [ ] Overview dashboard mostrando dados
- [ ] Agents dashboard com mÃ©tricas de todos agentes
- [ ] Federal APIs dashboard rastreando APIs externas
- [ ] SLO/SLA dashboard calculando uptime
- [ ] System Performance com mÃ©tricas de infra
- [ ] Zumbi dashboard com anomalias

### Alertas Configurados

- [ ] Regras de alerta carregadas
- [ ] Alertmanager configurado
- [ ] NotificaÃ§Ãµes testadas (Slack/Email/PagerDuty)
- [ ] On-call rotation definida

### ProduÃ§Ã£o

- [ ] Dashboards em produÃ§Ã£o (Railway)
- [ ] Prometheus persistence configurado
- [ ] Grafana com autenticaÃ§Ã£o
- [ ] Backup de dashboards
- [ ] DocumentaÃ§Ã£o atualizada

---

## ğŸ¯ PrÃ³ximos Passos

### Melhorias Planejadas

1. **Tracing DistribuÃ­do** (Jaeger integration)
   - Rastreamento end-to-end de requisiÃ§Ãµes
   - VisualizaÃ§Ã£o de latÃªncia por componente
   - Debug de performance multi-serviÃ§o

2. **Logs Centralizados** (Loki integration)
   - AgregaÃ§Ã£o de logs de todos componentes
   - Busca e filtros avanÃ§ados
   - CorrelaÃ§Ã£o com mÃ©tricas e traces

3. **Alertas Preditivos** (ML-based)
   - DetecÃ§Ã£o de anomalias em mÃ©tricas
   - Alertas proativos antes de SLA breach
   - Capacity planning automÃ¡tico

4. **Dashboard Mobile**
   - App mobile para monitoramento
   - NotificaÃ§Ãµes push
   - AÃ§Ãµes rÃ¡pidas (restart, scale)

---

## ğŸ“ Suporte

**Mantenedor**: Anderson Henrique da Silva
**Email**: [Configurar]
**LocalizaÃ§Ã£o**: Minas Gerais, Brasil

**Reportar Problemas**:
- GitHub Issues: [Configurar]
- Slack: #ops-monitoring
- On-call: [Configurar PagerDuty]

---

**Ãšltima AtualizaÃ§Ã£o**: 2025-10-30
**VersÃ£o do Documento**: 1.0
**Status**: âœ… ProduÃ§Ã£o
