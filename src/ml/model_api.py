"""
API de Deployment para Cidad√£o.AI

Interface completa para servir o modelo especializado em transpar√™ncia p√∫blica.
Similar ao padr√£o Kimi K2, mas otimizado para an√°lise governamental brasileira.
"""

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Union, Generator
import asyncio
import torch
import json
import logging
from pathlib import Path
from datetime import datetime
import uvicorn
from contextlib import asynccontextmanager
import tempfile
import pandas as pd
from io import StringIO

from .cidadao_model import CidadaoAIForTransparency, create_cidadao_model
from .training_pipeline import TransparencyDataset
from transformers import AutoTokenizer

logger = logging.getLogger(__name__)


# === MODELOS DE REQUEST/RESPONSE ===

class TransparencyAnalysisRequest(BaseModel):
    """Request para an√°lise de transpar√™ncia"""
    
    text: str = Field(..., description="Texto para an√°lise (contrato, despesa, etc.)")
    analysis_type: str = Field(
        default="complete",
        description="Tipo de an√°lise: 'anomaly', 'financial', 'legal', 'complete'"
    )
    include_explanation: bool = Field(
        default=True,
        description="Incluir explica√ß√£o detalhada dos resultados"
    )
    confidence_threshold: float = Field(
        default=0.7,
        description="Limiar de confian√ßa para alertas",
        ge=0.0,
        le=1.0
    )


class BatchAnalysisRequest(BaseModel):
    """Request para an√°lise em lote"""
    
    texts: List[str] = Field(..., description="Lista de textos para an√°lise")
    analysis_type: str = Field(default="complete")
    include_explanation: bool = Field(default=True)
    format: str = Field(default="json", description="Formato de sa√≠da: 'json' ou 'csv'")


class ChatRequest(BaseModel):
    """Request para chat com Cidad√£o.AI"""
    
    messages: List[Dict[str, str]] = Field(..., description="Hist√≥rico de mensagens")
    temperature: float = Field(default=0.6, ge=0.0, le=2.0)
    max_tokens: int = Field(default=512, ge=1, le=2048)
    stream: bool = Field(default=False, description="Usar streaming de resposta")
    tools: Optional[List[Dict]] = Field(default=None, description="Ferramentas dispon√≠veis")


class TransparencyAnalysisResponse(BaseModel):
    """Response da an√°lise de transpar√™ncia"""
    
    analysis_id: str = Field(..., description="ID √∫nico da an√°lise")
    text: str = Field(..., description="Texto analisado")
    timestamp: str = Field(..., description="Timestamp da an√°lise")
    
    # Resultados de anomalia
    anomaly_detection: Optional[Dict] = Field(None, description="Resultados de detec√ß√£o de anomalias")
    
    # Resultados financeiros
    financial_analysis: Optional[Dict] = Field(None, description="An√°lise de risco financeiro")
    
    # Resultados legais
    legal_compliance: Optional[Dict] = Field(None, description="Verifica√ß√£o de conformidade legal")
    
    # Resumo executivo
    executive_summary: Dict = Field(..., description="Resumo executivo da an√°lise")
    
    # Recomenda√ß√µes
    recommendations: List[str] = Field(..., description="Recomenda√ß√µes baseadas na an√°lise")
    
    # Metadados
    confidence: float = Field(..., description="Confian√ßa geral da an√°lise")
    processing_time: float = Field(..., description="Tempo de processamento em segundos")


class ChatResponse(BaseModel):
    """Response do chat"""
    
    message: str = Field(..., description="Resposta do assistente")
    tools_used: Optional[List[str]] = Field(None, description="Ferramentas utilizadas")
    confidence: float = Field(..., description="Confian√ßa da resposta")
    sources: Optional[List[str]] = Field(None, description="Fontes consultadas")


class ModelInfoResponse(BaseModel):
    """Informa√ß√µes do modelo"""
    
    model_name: str = Field(..., description="Nome do modelo")
    version: str = Field(..., description="Vers√£o do modelo")
    specialization: List[str] = Field(..., description="Tarefas especializadas")
    total_parameters: int = Field(..., description="N√∫mero total de par√¢metros")
    training_data: Dict = Field(..., description="Informa√ß√µes sobre dados de treinamento")
    performance_metrics: Dict = Field(..., description="M√©tricas de performance")


# === GERENCIADOR DE MODELO ===

class CidadaoAIManager:
    """Gerenciador do modelo Cidad√£o.AI"""
    
    def __init__(self, model_path: Optional[str] = None):
        self.model_path = model_path
        self.model: Optional[CidadaoAIForTransparency] = None
        self.tokenizer: Optional[AutoTokenizer] = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.loaded = False
        
        # Estat√≠sticas de uso
        self.usage_stats = {
            "total_requests": 0,
            "anomaly_detections": 0,
            "financial_analyses": 0,
            "legal_checks": 0,
            "chat_requests": 0,
            "average_processing_time": 0.0
        }

    async def load_model(self):
        """Carregar modelo"""
        try:
            logger.info("ü§ñ Carregando Cidad√£o.AI...")
            
            if self.model_path and Path(self.model_path).exists():
                # Carregar modelo treinado
                self.model = CidadaoAIForTransparency.load_model(self.model_path)
                logger.info(f"‚úÖ Modelo carregado de {self.model_path}")
            else:
                # Carregar modelo base
                self.model = create_cidadao_model(
                    specialized_tasks=["all"],
                    model_size="medium"
                )
                logger.info("‚úÖ Modelo base criado")
            
            # Carregar tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-medium")
            self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # Mover para device
            self.model.to(self.device)
            self.model.eval()
            
            self.loaded = True
            logger.info(f"üéØ Modelo pronto no device: {self.device}")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar modelo: {e}")
            raise

    async def analyze_transparency(
        self, 
        request: TransparencyAnalysisRequest
    ) -> TransparencyAnalysisResponse:
        """Executar an√°lise de transpar√™ncia"""
        
        if not self.loaded:
            raise HTTPException(status_code=503, detail="Modelo n√£o carregado")
        
        start_time = datetime.now()
        
        try:
            # Tokenizar texto
            inputs = self.tokenizer(
                request.text,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            ).to(self.device)
            
            # Executar an√°lises baseadas no tipo solicitado
            results = {}
            
            if request.analysis_type in ["anomaly", "complete"]:
                anomaly_results = self.model.detect_anomalies(
                    input_ids=inputs["input_ids"],
                    attention_mask=inputs["attention_mask"]
                )
                results["anomaly_detection"] = anomaly_results
            
            if request.analysis_type in ["financial", "complete"]:
                financial_results = self.model.analyze_financial_risk(
                    input_ids=inputs["input_ids"],
                    attention_mask=inputs["attention_mask"]
                )
                results["financial_analysis"] = financial_results
            
            if request.analysis_type in ["legal", "complete"]:
                legal_results = self.model.check_legal_compliance(
                    input_ids=inputs["input_ids"],
                    attention_mask=inputs["attention_mask"]
                )
                results["legal_compliance"] = legal_results
            
            # Gerar resumo executivo e recomenda√ß√µes
            executive_summary, recommendations, overall_confidence = self._generate_summary(
                results, request.confidence_threshold
            )
            
            # Calcular tempo de processamento
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # Atualizar estat√≠sticas
            self.usage_stats["total_requests"] += 1
            if "anomaly_detection" in results:
                self.usage_stats["anomaly_detections"] += 1
            if "financial_analysis" in results:
                self.usage_stats["financial_analyses"] += 1
            if "legal_compliance" in results:
                self.usage_stats["legal_checks"] += 1
            
            # Atualizar tempo m√©dio
            current_avg = self.usage_stats["average_processing_time"]
            total_requests = self.usage_stats["total_requests"]
            self.usage_stats["average_processing_time"] = (
                (current_avg * (total_requests - 1) + processing_time) / total_requests
            )
            
            # Construir response
            response = TransparencyAnalysisResponse(
                analysis_id=f"cidadao_{int(start_time.timestamp())}",
                text=request.text,
                timestamp=start_time.isoformat(),
                anomaly_detection=results.get("anomaly_detection"),
                financial_analysis=results.get("financial_analysis"),
                legal_compliance=results.get("legal_compliance"),
                executive_summary=executive_summary,
                recommendations=recommendations,
                confidence=overall_confidence,
                processing_time=processing_time
            )
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise: {e}")
            raise HTTPException(status_code=500, detail=f"Erro na an√°lise: {str(e)}")

    async def batch_analyze(
        self, 
        request: BatchAnalysisRequest
    ) -> Union[List[TransparencyAnalysisResponse], str]:
        """An√°lise em lote"""
        
        results = []
        
        for text in request.texts:
            analysis_request = TransparencyAnalysisRequest(
                text=text,
                analysis_type=request.analysis_type,
                include_explanation=request.include_explanation
            )
            
            result = await self.analyze_transparency(analysis_request)
            results.append(result)
        
        if request.format == "csv":
            return self._convert_to_csv(results)
        
        return results

    async def chat_completion(self, request: ChatRequest) -> Union[ChatResponse, Generator]:
        """Completa√ß√£o de chat"""
        
        if not self.loaded:
            raise HTTPException(status_code=503, detail="Modelo n√£o carregado")
        
        self.usage_stats["chat_requests"] += 1
        
        try:
            # Extrair √∫ltima mensagem do usu√°rio
            user_message = request.messages[-1]["content"]
            
            # Detectar se √© uma pergunta sobre transpar√™ncia
            transparency_keywords = [
                "contrato", "licita√ß√£o", "despesa", "gasto", "anomalia",
                "suspeito", "irregular", "transpar√™ncia", "corrup√ß√£o"
            ]
            
            is_transparency_query = any(
                keyword in user_message.lower() 
                for keyword in transparency_keywords
            )
            
            if is_transparency_query:
                # Usar an√°lise especializada
                analysis_request = TransparencyAnalysisRequest(
                    text=user_message,
                    analysis_type="complete"
                )
                
                analysis_result = await self.analyze_transparency(analysis_request)
                
                # Gerar resposta em linguagem natural
                response_message = self._format_analysis_for_chat(analysis_result)
                
                return ChatResponse(
                    message=response_message,
                    tools_used=["transparency_analysis"],
                    confidence=analysis_result.confidence,
                    sources=["Portal da Transpar√™ncia", "Cidad√£o.AI Analysis"]
                )
            else:
                # Resposta geral do chatbot
                response_message = self._generate_general_response(user_message)
                
                return ChatResponse(
                    message=response_message,
                    tools_used=None,
                    confidence=0.8,
                    sources=None
                )
                
        except Exception as e:
            logger.error(f"‚ùå Erro no chat: {e}")
            raise HTTPException(status_code=500, detail=f"Erro no chat: {str(e)}")

    def _generate_summary(
        self, 
        results: Dict, 
        confidence_threshold: float
    ) -> Tuple[Dict, List[str], float]:
        """Gerar resumo executivo e recomenda√ß√µes"""
        
        summary = {
            "overall_risk": "Baixo",
            "main_findings": [],
            "alert_level": "Verde"
        }
        
        recommendations = []
        confidences = []
        
        # An√°lise de anomalias
        if "anomaly_detection" in results:
            anomaly_data = results["anomaly_detection"]
            anomalous_count = anomaly_data["summary"]["anomalous_count"]
            
            if anomalous_count > 0:
                summary["main_findings"].append(f"{anomalous_count} anomalias detectadas")
                summary["alert_level"] = "Vermelho"
                summary["overall_risk"] = "Alto"
                recommendations.append("üö® Investiga√ß√£o imediata necess√°ria devido a anomalias detectadas")
            
            # Coletar confian√ßa m√©dia
            high_conf_count = anomaly_data["summary"]["high_confidence_count"]
            total_samples = anomaly_data["summary"]["total_samples"]
            if total_samples > 0:
                confidences.append(high_conf_count / total_samples)
        
        # An√°lise financeira
        if "financial_analysis" in results:
            financial_data = results["financial_analysis"]
            high_risk_count = financial_data["summary"]["high_risk_count"]
            avg_value = financial_data["summary"]["average_estimated_value"]
            
            if high_risk_count > 0:
                summary["main_findings"].append(f"{high_risk_count} contratos de alto risco financeiro")
                if summary["overall_risk"] == "Baixo":
                    summary["overall_risk"] = "M√©dio"
                    summary["alert_level"] = "Amarelo"
                recommendations.append("‚ö†Ô∏è Revis√£o financeira recomendada para contratos de alto risco")
            
            if avg_value > 10000000:  # > 10M
                summary["main_findings"].append(f"Valor m√©dio elevado: R$ {avg_value:,.2f}")
        
        # An√°lise legal
        if "legal_compliance" in results:
            legal_data = results["legal_compliance"]
            compliance_rate = legal_data["summary"]["compliance_rate"]
            
            if compliance_rate < 0.8:
                summary["main_findings"].append(f"Taxa de conformidade baixa: {compliance_rate:.1%}")
                recommendations.append("üìã Revis√£o de processos de compliance necess√°ria")
        
        # Calcular confian√ßa geral
        overall_confidence = sum(confidences) / len(confidences) if confidences else 0.7
        
        # Recomenda√ß√µes padr√£o
        if not recommendations:
            recommendations.append("‚úÖ An√°lise n√£o identificou problemas cr√≠ticos")
        
        return summary, recommendations, overall_confidence

    def _format_analysis_for_chat(self, analysis: TransparencyAnalysisResponse) -> str:
        """Formatar an√°lise para resposta de chat"""
        
        response_parts = []
        
        # Resumo executivo
        summary = analysis.executive_summary
        response_parts.append(f"üìä **An√°lise de Transpar√™ncia**")
        response_parts.append(f"üéØ **N√≠vel de Risco**: {summary['overall_risk']}")
        response_parts.append(f"üö® **Alerta**: {summary['alert_level']}")
        
        # Principais descobertas
        if summary["main_findings"]:
            response_parts.append("\nüîç **Principais Descobertas**:")
            for finding in summary["main_findings"]:
                response_parts.append(f"‚Ä¢ {finding}")
        
        # Recomenda√ß√µes
        response_parts.append("\nüí° **Recomenda√ß√µes**:")
        for rec in analysis.recommendations:
            response_parts.append(f"‚Ä¢ {rec}")
        
        # Detalhes t√©cnicos
        if analysis.anomaly_detection:
            anomaly_count = analysis.anomaly_detection["summary"]["anomalous_count"]
            if anomaly_count > 0:
                response_parts.append(f"\n‚ö†Ô∏è **Anomalias Detectadas**: {anomaly_count}")
        
        if analysis.financial_analysis:
            high_risk = analysis.financial_analysis["summary"]["high_risk_count"]
            if high_risk > 0:
                response_parts.append(f"üí∞ **Contratos Alto Risco**: {high_risk}")
        
        # Confian√ßa
        response_parts.append(f"\nüìà **Confian√ßa da An√°lise**: {analysis.confidence:.1%}")
        
        return "\n".join(response_parts)

    def _generate_general_response(self, message: str) -> str:
        """Gerar resposta geral do chatbot"""
        
        # Respostas baseadas em palavras-chave
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["ol√°", "oi", "bom dia", "boa tarde"]):
            return ("Ol√°! Sou o Cidad√£o.AI, seu assistente de IA especializado em transpar√™ncia p√∫blica brasileira. "
                   "Posso ajudar voc√™ a analisar contratos, detectar anomalias e verificar conformidade legal. "
                   "Como posso ajud√°-lo hoje?")
        
        elif any(word in message_lower for word in ["ajuda", "help", "como"]):
            return ("ü§ñ **Cidad√£o.AI - Suas Funcionalidades**\n\n"
                   "‚Ä¢ üîç **An√°lise de Anomalias**: Detectar padr√µes suspeitos em contratos\n"
                   "‚Ä¢ üí∞ **An√°lise Financeira**: Avaliar riscos em gastos p√∫blicos\n"
                   "‚Ä¢ ‚öñÔ∏è **Conformidade Legal**: Verificar adequa√ß√£o √†s normas\n"
                   "‚Ä¢ üìä **Relat√≥rios**: Gerar an√°lises detalhadas\n\n"
                   "Compartilhe um texto de contrato ou despesa p√∫blica para an√°lise!")
        
        elif any(word in message_lower for word in ["obrigado", "obrigada", "valeu"]):
            return ("Fico feliz em ajudar! üòä A transpar√™ncia p√∫blica √© fundamental para a democracia. "
                   "Se precisar de mais an√°lises, estarei aqui!")
        
        else:
            return ("Entendo que voc√™ tem uma pergunta. Como sou especializado em an√°lise de transpar√™ncia p√∫blica, "
                   "funciono melhor quando voc√™ compartilha textos de contratos, licita√ß√µes ou despesas para an√°lise. "
                   "Voc√™ poderia reformular sua pergunta incluindo dados de transpar√™ncia?")

    def _convert_to_csv(self, results: List[TransparencyAnalysisResponse]) -> str:
        """Converter resultados para CSV"""
        
        rows = []
        
        for result in results:
            row = {
                "analysis_id": result.analysis_id,
                "timestamp": result.timestamp,
                "text_preview": result.text[:100] + "..." if len(result.text) > 100 else result.text,
                "overall_risk": result.executive_summary["overall_risk"],
                "alert_level": result.executive_summary["alert_level"],
                "confidence": result.confidence,
                "processing_time": result.processing_time
            }
            
            # Adicionar detalhes de anomalia
            if result.anomaly_detection:
                row["anomalous_count"] = result.anomaly_detection["summary"]["anomalous_count"]
            
            # Adicionar detalhes financeiros
            if result.financial_analysis:
                row["high_risk_count"] = result.financial_analysis["summary"]["high_risk_count"]
                row["avg_estimated_value"] = result.financial_analysis["summary"]["average_estimated_value"]
            
            # Adicionar conformidade legal
            if result.legal_compliance:
                row["compliance_rate"] = result.legal_compliance["summary"]["compliance_rate"]
            
            rows.append(row)
        
        # Converter para CSV
        df = pd.DataFrame(rows)
        csv_buffer = StringIO()
        df.to_csv(csv_buffer, index=False)
        
        return csv_buffer.getvalue()

    def get_model_info(self) -> ModelInfoResponse:
        """Obter informa√ß√µes do modelo"""
        
        if not self.loaded:
            raise HTTPException(status_code=503, detail="Modelo n√£o carregado")
        
        # Contar par√¢metros
        total_params = sum(p.numel() for p in self.model.parameters())
        
        return ModelInfoResponse(
            model_name="Cidad√£o.AI",
            version="1.0.0",
            specialization=["anomaly_detection", "financial_analysis", "legal_compliance"],
            total_parameters=total_params,
            training_data={
                "source": "Portal da Transpar√™ncia + Dados Sint√©ticos",
                "languages": ["pt-BR"],
                "domains": ["contratos_p√∫blicos", "licita√ß√µes", "despesas_governo"]
            },
            performance_metrics=self.usage_stats
        )


# === APLICA√á√ÉO FASTAPI ===

# Inst√¢ncia global do gerenciador
model_manager = CidadaoAIManager()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gerenciar ciclo de vida da aplica√ß√£o"""
    # Startup
    await model_manager.load_model()
    yield
    # Shutdown
    pass

# Criar aplica√ß√£o FastAPI
app = FastAPI(
    title="Cidad√£o.AI API",
    description="API de IA especializada em an√°lise de transpar√™ncia p√∫blica brasileira",
    version="1.0.0",
    lifespan=lifespan
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# === ENDPOINTS ===

@app.get("/", summary="Informa√ß√µes da API")
async def root():
    """Endpoint raiz com informa√ß√µes da API"""
    return {
        "name": "Cidad√£o.AI API",
        "version": "1.0.0",
        "description": "API de IA especializada em transpar√™ncia p√∫blica brasileira",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health", summary="Health Check")
async def health_check():
    """Verificar sa√∫de da API"""
    return {
        "status": "healthy" if model_manager.loaded else "loading",
        "model_loaded": model_manager.loaded,
        "device": str(model_manager.device),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/model/info", response_model=ModelInfoResponse, summary="Informa√ß√µes do Modelo")
async def get_model_info():
    """Obter informa√ß√µes detalhadas do modelo"""
    return model_manager.get_model_info()

@app.post("/analyze", response_model=TransparencyAnalysisResponse, summary="An√°lise de Transpar√™ncia")
async def analyze_transparency(request: TransparencyAnalysisRequest):
    """
    Analisar texto para detectar anomalias, riscos financeiros e conformidade legal
    
    - **text**: Texto do contrato, despesa ou licita√ß√£o para an√°lise
    - **analysis_type**: Tipo de an√°lise (anomaly, financial, legal, complete)
    - **include_explanation**: Incluir explica√ß√µes detalhadas
    - **confidence_threshold**: Limiar de confian√ßa para alertas
    """
    return await model_manager.analyze_transparency(request)

@app.post("/analyze/batch", summary="An√°lise em Lote")
async def batch_analyze(request: BatchAnalysisRequest):
    """
    Analisar m√∫ltiplos textos em lote
    
    - **texts**: Lista de textos para an√°lise
    - **analysis_type**: Tipo de an√°lise
    - **format**: Formato de sa√≠da (json ou csv)
    """
    results = await model_manager.batch_analyze(request)
    
    if request.format == "csv":
        return StreamingResponse(
            iter([results]),
            media_type="text/csv",
            headers={"Content-Disposition": "attachment; filename=cidadao_analysis.csv"}
        )
    
    return results

@app.post("/chat", response_model=ChatResponse, summary="Chat com Cidad√£o.AI")
async def chat_completion(request: ChatRequest):
    """
    Conversar com o Cidad√£o.AI sobre transpar√™ncia p√∫blica
    
    - **messages**: Hist√≥rico de mensagens
    - **temperature**: Criatividade da resposta
    - **max_tokens**: Tamanho m√°ximo da resposta
    """
    return await model_manager.chat_completion(request)

@app.post("/upload", summary="Upload de Arquivo para An√°lise")
async def upload_file(file: UploadFile = File(...)):
    """
    Fazer upload de arquivo (CSV, TXT, JSON) para an√°lise em lote
    """
    
    if not file.filename.endswith(('.csv', '.txt', '.json')):
        raise HTTPException(
            status_code=400, 
            detail="Formato n√£o suportado. Use CSV, TXT ou JSON."
        )
    
    try:
        content = await file.read()
        
        if file.filename.endswith('.csv'):
            # Processar CSV
            df = pd.read_csv(StringIO(content.decode('utf-8')))
            texts = df.iloc[:, 0].tolist()  # Primeira coluna
            
        elif file.filename.endswith('.txt'):
            # Processar TXT (uma linha por texto)
            texts = content.decode('utf-8').strip().split('\n')
            
        elif file.filename.endswith('.json'):
            # Processar JSON
            data = json.loads(content.decode('utf-8'))
            if isinstance(data, list):
                texts = [str(item) for item in data]
            else:
                texts = [str(data)]
        
        # Limitar a 100 textos para evitar sobrecarga
        texts = texts[:100]
        
        # Executar an√°lise em lote
        batch_request = BatchAnalysisRequest(
            texts=texts,
            analysis_type="complete",
            format="json"
        )
        
        results = await model_manager.batch_analyze(batch_request)
        
        return {
            "filename": file.filename,
            "processed_count": len(texts),
            "results": results
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erro no upload: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao processar arquivo: {str(e)}")

@app.get("/stats", summary="Estat√≠sticas de Uso")
async def get_usage_stats():
    """Obter estat√≠sticas de uso da API"""
    return model_manager.usage_stats

@app.get("/examples", summary="Exemplos de Uso")
async def get_examples():
    """Obter exemplos de uso da API"""
    
    return {
        "transparency_analysis": {
            "description": "An√°lise completa de transpar√™ncia",
            "example": {
                "text": "Contrato para aquisi√ß√£o de equipamentos m√©dicos no valor de R$ 2.500.000,00 firmado entre Minist√©rio da Sa√∫de e Empresa XYZ LTDA via dispensa de licita√ß√£o.",
                "analysis_type": "complete",
                "include_explanation": True
            }
        },
        "anomaly_detection": {
            "description": "Detectar apenas anomalias",
            "example": {
                "text": "Contrato emergencial sem licita√ß√£o para fornecimento de insumos hospitalares. Valor: R$ 15.000.000,00. Empresa com CNPJ irregular.",
                "analysis_type": "anomaly"
            }
        },
        "chat": {
            "description": "Conversar sobre transpar√™ncia",
            "example": {
                "messages": [
                    {"role": "user", "content": "Analise este contrato: Aquisi√ß√£o de medicamentos por R$ 5 milh√µes sem licita√ß√£o."}
                ]
            }
        }
    }


# === EXECU√á√ÉO ===

if __name__ == "__main__":
    # Configurar logging
    logging.basicConfig(level=logging.INFO)
    
    # Executar servidor
    uvicorn.run(
        "src.ml.model_api:app",
        host="0.0.0.0",
        port=8001,
        reload=True,
        log_level="info"
    )