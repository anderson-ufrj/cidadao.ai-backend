#!/usr/bin/env python3
"""
Testar o agente Zumbi diretamente via API
"""

import json

import httpx

API_URL = "https://cidadao-api-production.up.railway.app"


def test_zumbi_agent():
    """Testa o agente Zumbi diretamente"""

    print("\n" + "=" * 60)
    print("üîç TESTE DIRETO DO AGENTE ZUMBI")
    print("=" * 60)

    with httpx.Client(timeout=30.0) as client:
        # Testar endpoint do Zumbi
        print("\n1. Testando endpoint do agente Zumbi...")

        payload = {
            "query": "Detectar anomalias em contratos",
            "data_source": "contracts",
            "filters": {"ano": 2024, "codigo_orgao": "26000"},
            "anomaly_types": ["price"],
        }

        try:
            response = client.post(
                f"{API_URL}/api/agents/zumbi/analyze", json=payload, timeout=30.0
            )

            print(f"   Status: {response.status_code}")

            if response.status_code == 200:
                print("   ‚úÖ Agente respondeu!")
                result = response.json()
                print(f"   Resposta: {json.dumps(result, indent=2)[:500]}...")
            elif response.status_code == 404:
                print("   ‚ö†Ô∏è Endpoint n√£o encontrado")
                print("   O endpoint direto do agente pode n√£o estar dispon√≠vel")
            else:
                print(f"   ‚ùå Erro: {response.status_code}")
                print(f"   Resposta: {response.text[:200]}")

        except httpx.TimeoutException:
            print("   ‚è±Ô∏è Timeout - o agente est√° demorando muito para responder")
            print("   Poss√≠vel problema com a API do LLM (Groq/Maritaca)")
        except Exception as e:
            print(f"   ‚ùå Erro: {e}")


def check_llm_config():
    """Verifica configura√ß√£o de LLM"""

    print("\n" + "=" * 60)
    print("ü§ñ VERIFICA√á√ÉO DE LLM")
    print("=" * 60)

    print(
        """
POSS√çVEIS PROBLEMAS COM LLM:

1. GROQ_API_KEY:
   ‚Ä¢ Verifique se est√° configurada no Railway
   ‚Ä¢ Teste se a chave ainda √© v√°lida
   ‚Ä¢ Verifique rate limits (14K tokens/min)

2. MARITACA_API_KEY:
   ‚Ä¢ Alternativa para portugu√™s
   ‚Ä¢ Verifique se est√° configurada como fallback

3. TIMEOUT DO LLM:
   ‚Ä¢ O agente pode estar esperando resposta do LLM
   ‚Ä¢ Default timeout pode ser muito alto

4. VERIFICAR NO RAILWAY:
   ‚Ä¢ V√° em Settings ‚Üí Variables
   ‚Ä¢ Confirme que GROQ_API_KEY est√° presente
   ‚Ä¢ Adicione MARITACA_API_KEY como backup

5. LOGS PARA PROCURAR:
   ‚Ä¢ "groq_client" ou "maritaca_client"
   ‚Ä¢ "timeout" ou "rate limit"
   ‚Ä¢ "LLM" ou "completion"
"""
    )


def suggest_fixes():
    """Sugest√µes de corre√ß√µes"""

    print("\n" + "=" * 60)
    print("üîß SUGEST√ïES DE CORRE√á√ÉO")
    print("=" * 60)

    print(
        """
1. ADICIONAR TIMEOUT MENOR NO LLM:
   ‚Ä¢ Editar src/services/llm_service.py
   ‚Ä¢ Reduzir timeout para 30 segundos

2. ADICIONAR FALLBACK PARA MOCK:
   ‚Ä¢ Se LLM falhar, usar resposta mock
   ‚Ä¢ Permitir que investiga√ß√£o continue

3. VERIFICAR RATE LIMITS:
   ‚Ä¢ Groq: 14,400 tokens/min
   ‚Ä¢ Adicionar retry com backoff

4. TESTAR COM CURL:
   curl -X POST https://cidadao-api-production.up.railway.app/api/v1/investigations/start \
     -H "Content-Type: application/json" \
     -d '{"query":"Teste","data_source":"contracts","filters":{},"anomaly_types":["price"]}'

5. VERIFICAR LOGS EM TEMPO REAL:
   ‚Ä¢ Railway Dashboard ‚Üí Logs
   ‚Ä¢ Filtrar por "ERROR" ou "WARN"
"""
    )


if __name__ == "__main__":
    print("\nüöÄ DIAGN√ìSTICO DO PROBLEMA DE INVESTIGA√á√ÉO\n")

    # Testar agente diretamente
    test_zumbi_agent()

    # Verificar LLM
    check_llm_config()

    # Sugest√µes
    suggest_fixes()

    print("\n‚úÖ Diagn√≥stico conclu√≠do!")
    print("\nüìä RESUMO: A investiga√ß√£o est√° travando na chamada do LLM")
    print("   Provavelmente o GROQ_API_KEY n√£o est√° configurado ou expirou")
