"""
Emergency chat endpoint - Minimal dependencies, maximum reliability
This endpoint ensures the chat always works, even if other services fail
"""

import os
import json
from datetime import datetime
from typing import Dict, Any, Optional, List
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
import httpx
import random

from src.core import get_logger

logger = get_logger(__name__)

router = APIRouter(prefix="/api/v1/chat", tags=["chat-emergency"])

# Request/Response models
class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=1000)
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    session_id: str
    agent_id: str = "assistant"
    agent_name: str = "Assistente Cidad√£o.AI"
    message: str
    confidence: float = 0.95
    suggested_actions: List[str] = []
    metadata: Dict[str, Any] = {}

# Professional responses for common queries
RESPONSES = {
    "greeting": [
        "Ol√°! Sou o assistente do Cidad√£o.AI. Estou aqui para ajudar voc√™ a entender e investigar gastos p√∫blicos. Como posso ajudar?",
        "Bem-vindo ao Cidad√£o.AI! Posso ajudar voc√™ a analisar contratos, investigar gastos e entender melhor a transpar√™ncia p√∫blica.",
        "Oi! Sou especializado em transpar√™ncia p√∫blica. Posso investigar contratos, analisar gastos governamentais e muito mais. O que voc√™ gostaria de saber?"
    ],
    "investigation": [
        "Vou ajudar voc√™ a investigar. Posso analisar:\n‚Ä¢ Contratos e licita√ß√µes\n‚Ä¢ Gastos por √≥rg√£o p√∫blico\n‚Ä¢ Pagamentos a fornecedores\n‚Ä¢ Evolu√ß√£o temporal de despesas\n\nQual √°rea espec√≠fica voc√™ quer investigar?",
        "Entendi que voc√™ quer investigar gastos p√∫blicos. Tenho acesso a dados de contratos, fornecedores e √≥rg√£os p√∫blicos. Por onde gostaria de come√ßar?",
        "Perfeito! Posso investigar contratos suspeitos, analisar padr√µes de gastos e identificar anomalias. Me d√™ mais detalhes sobre o que voc√™ procura."
    ],
    "help": [
        "Posso ajudar voc√™ com:\n\nüìä **An√°lise de Contratos**: Investigar licita√ß√µes e contratos p√∫blicos\nüí∞ **Gastos P√∫blicos**: Acompanhar despesas governamentais\nüîç **Detec√ß√£o de Anomalias**: Identificar padr√µes irregulares\nüìà **Relat√≥rios**: Gerar an√°lises detalhadas\n\nO que voc√™ gostaria de fazer?",
        "O Cidad√£o.AI oferece v√°rias funcionalidades:\n‚Ä¢ Investigar contratos espec√≠ficos\n‚Ä¢ Analisar gastos de √≥rg√£os p√∫blicos\n‚Ä¢ Comparar fornecedores\n‚Ä¢ Detectar anomalias em pagamentos\n‚Ä¢ Gerar relat√≥rios de transpar√™ncia\n\nComo posso ajudar?",
        "Aqui est√° o que posso fazer por voc√™:\n1. Buscar informa√ß√µes sobre contratos\n2. Analisar tend√™ncias de gastos\n3. Identificar fornecedores frequentes\n4. Detectar poss√≠veis irregularidades\n5. Criar visualiza√ß√µes de dados\n\nQual dessas op√ß√µes te interessa?"
    ],
    "default": [
        "Entendi sua pergunta. Para te ajudar melhor com transpar√™ncia p√∫blica, voc√™ pode:\n‚Ä¢ Pedir para investigar contratos espec√≠ficos\n‚Ä¢ Solicitar an√°lise de gastos de um √≥rg√£o\n‚Ä¢ Buscar informa√ß√µes sobre fornecedores\n\nComo posso ajudar?",
        "Interessante sua quest√£o! No contexto de transpar√™ncia p√∫blica, posso ajudar voc√™ a entender gastos governamentais, contratos e licita√ß√µes. Que tipo de informa√ß√£o voc√™ procura?",
        "Certo! Como assistente de transpar√™ncia, posso investigar dados p√∫blicos, analisar contratos e identificar padr√µes. Me conte mais sobre o que voc√™ quer descobrir."
    ]
}

def detect_intent(message: str) -> str:
    """Simple intent detection based on keywords"""
    message_lower = message.lower()
    
    if any(word in message_lower for word in ["ol√°", "oi", "bom dia", "boa tarde", "boa noite", "prazer"]):
        return "greeting"
    elif any(word in message_lower for word in ["investigar", "verificar", "analisar", "buscar", "procurar"]):
        return "investigation"
    elif any(word in message_lower for word in ["ajuda", "ajudar", "pode", "consegue", "o que", "como"]):
        return "help"
    else:
        return "default"

async def try_maritaca(message: str) -> Optional[str]:
    """Try to get response from Maritaca AI"""
    api_key = os.getenv("MARITACA_API_KEY")
    if not api_key:
        return None
        
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                "https://chat.maritaca.ai/api/chat/inference",
                headers={"authorization": f"Bearer {api_key}"},
                json={
                    "messages": [
                        {
                            "role": "system", 
                            "content": "Voc√™ √© um assistente especializado em transpar√™ncia p√∫blica brasileira. Ajude os cidad√£os a entender gastos governamentais, contratos e licita√ß√µes. Seja claro, objetivo e sempre sugira a√ß√µes espec√≠ficas."
                        },
                        {"role": "user", "content": message}
                    ],
                    "model": "sabia-3",
                    "temperature": 0.7,
                    "max_tokens": 400
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("answer", None)
                
    except Exception as e:
        logger.warning(f"Maritaca request failed: {e}")
    
    return None

@router.post("/emergency", response_model=ChatResponse)
async def chat_emergency(request: ChatRequest) -> ChatResponse:
    """
    Emergency chat endpoint - Always returns a valid response
    Tries Maritaca AI first, falls back to intelligent responses
    """
    session_id = request.session_id or f"emergency_{datetime.now().timestamp()}"
    
    # Try Maritaca first
    maritaca_response = await try_maritaca(request.message)
    
    if maritaca_response:
        return ChatResponse(
            session_id=session_id,
            agent_id="maritaca",
            agent_name="Assistente Cidad√£o.AI (Maritaca)",
            message=maritaca_response,
            confidence=0.95,
            suggested_actions=["investigate_contracts", "analyze_expenses", "generate_report"],
            metadata={
                "model": "sabia-3",
                "backend": "maritaca_ai",
                "timestamp": datetime.utcnow().isoformat()
            }
        )
    
    # Fallback to intelligent responses
    intent = detect_intent(request.message)
    response_list = RESPONSES.get(intent, RESPONSES["default"])
    selected_response = random.choice(response_list)
    
    # Determine suggested actions based on intent
    if intent == "greeting":
        actions = ["start_investigation", "view_recent_contracts", "help"]
    elif intent == "investigation":
        actions = ["search_contracts", "analyze_supplier", "view_timeline"]
    elif intent == "help":
        actions = ["examples", "start_investigation", "documentation"]
    else:
        actions = ["help", "start_investigation", "search"]
    
    return ChatResponse(
        session_id=session_id,
        agent_id="system",
        agent_name="Assistente Cidad√£o.AI",
        message=selected_response,
        confidence=0.85,
        suggested_actions=actions,
        metadata={
            "backend": "intelligent_fallback",
            "intent": intent,
            "timestamp": datetime.utcnow().isoformat()
        }
    )

@router.get("/emergency/health")
async def emergency_health():
    """Health check for emergency endpoint"""
    maritaca_available = bool(os.getenv("MARITACA_API_KEY"))
    
    return {
        "status": "operational",
        "endpoint": "/api/v1/chat/emergency",
        "maritaca_configured": maritaca_available,
        "fallback_ready": True,
        "timestamp": datetime.utcnow().isoformat()
    }