#!/usr/bin/env python3
"""
Teste de integra√ß√£o com Maritaca AI
Verifica se o sistema est√° configurado corretamente para usar Maritaca
"""

import asyncio
import os
import sys
from datetime import datetime

# Adicionar o diret√≥rio src ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configurar vari√°veis de ambiente para teste
os.environ["JWT_SECRET_KEY"] = "test_jwt_secret"
os.environ["SECRET_KEY"] = "test_secret"

# IMPORTANTE: Configure a API Key da Maritaca aqui ou no .env
# os.environ["MARITACA_API_KEY"] = "sk-xxxxx"  # Substitua com sua chave

# For√ßar o uso do Maritaca como provider
os.environ["LLM_PROVIDER"] = "maritaca"
os.environ["LLM_MODEL_NAME"] = "sabiazinho-3"  # Modelo mais econ√¥mico


async def test_maritaca_provider():
    """Testa se o provider Maritaca est√° funcionando"""

    print("\n" + "=" * 60)
    print("ü§ñ TESTE DE INTEGRA√á√ÉO COM MARITACA AI")
    print("=" * 60)

    # 1. Verificar configura√ß√£o
    print("\n1. Verificando configura√ß√£o...")
    from src.core import settings

    print(f"   LLM Provider: {settings.llm_provider}")
    print(f"   LLM Model: {settings.llm_model_name}")

    if settings.maritaca_api_key:
        api_key_preview = str(settings.maritaca_api_key.get_secret_value())[:10] + "..."
        print(f"   Maritaca API Key: {api_key_preview}")
    else:
        print("   ‚ö†Ô∏è  MARITACA_API_KEY n√£o configurada!")
        print("   Configure a vari√°vel de ambiente MARITACA_API_KEY")
        return False

    # 2. Testar cria√ß√£o do LLM Manager
    print("\n2. Criando LLM Manager com Maritaca...")
    try:
        from src.llm.providers import LLMRequest, create_llm_manager

        llm_manager = create_llm_manager(
            primary_provider="maritaca",
            enable_fallback=False,  # N√£o usar fallback para testar s√≥ Maritaca
        )
        print("   ‚úÖ LLM Manager criado com sucesso")
    except Exception as e:
        print(f"   ‚ùå Erro ao criar LLM Manager: {e}")
        import traceback

        traceback.print_exc()
        return False

    # 3. Testar uma requisi√ß√£o simples
    print("\n3. Testando requisi√ß√£o ao Maritaca...")
    try:
        request = LLMRequest(
            prompt="Ol√°! Responda em portugu√™s: Qual √© a capital do Brasil?",
            max_tokens=100,
            temperature=0.5,
        )

        response = await llm_manager.complete(request)

        print("   ‚úÖ Resposta recebida!")
        print(f"   Conte√∫do: {response.content[:200]}...")
        print(f"   Provider usado: {response.provider}")
        print(f"   Tempo de resposta: {response.response_time:.2f}s")
        print(f"   Tokens usados: {response.usage.get('total_tokens', 0)}")

        return True

    except Exception as e:
        print(f"   ‚ùå Erro na requisi√ß√£o: {e}")
        return False
    finally:
        await llm_manager.close()


async def test_investigation_with_maritaca():
    """Testa uma investiga√ß√£o usando Maritaca"""

    print("\n" + "=" * 60)
    print("üîç TESTE DE INVESTIGA√á√ÉO COM MARITACA")
    print("=" * 60)

    # Verificar se Maritaca est√° configurado
    from src.core import settings

    if not settings.maritaca_api_key:
        print("   ‚ö†Ô∏è  MARITACA_API_KEY n√£o configurada!")
        print("   Pule este teste ou configure a API key")
        return False

    print("\n1. Importando agente Zumbi...")
    try:
        from src.agents.deodoro import AgentContext, AgentMessage
        from src.agents.zumbi import ZumbiAgent

        agent = ZumbiAgent()
        print("   ‚úÖ Agente Zumbi importado")
    except Exception as e:
        print(f"   ‚ùå Erro ao importar: {e}")
        return False

    print("\n2. Criando mensagem de teste...")
    message = AgentMessage(
        content={
            "query": "Detectar anomalias em contratos usando Maritaca AI",
            "data": [
                {"valor": 10000, "fornecedor": "Empresa A", "modalidade": "Preg√£o"},
                {
                    "valor": 500000,
                    "fornecedor": "Empresa B",
                    "modalidade": "Preg√£o",
                },  # Anomalia
                {"valor": 12000, "fornecedor": "Empresa C", "modalidade": "Preg√£o"},
            ],
            "anomaly_types": ["price"],
        },
        sender_id="test_user",
        receiver_id="zumbi",
    )

    context = AgentContext()

    print("\n3. Processando com agente...")
    try:
        start_time = datetime.now()
        response = await agent.process(message, context)
        end_time = datetime.now()

        print("   ‚úÖ Processamento conclu√≠do!")
        print(f"   Status: {response.status}")
        print(f"   Tempo: {(end_time - start_time).total_seconds():.2f}s")

        if response.content.get("anomalies"):
            print(f"   Anomalias detectadas: {len(response.content['anomalies'])}")

        return response.status == "success"

    except Exception as e:
        print(f"   ‚ùå Erro no processamento: {e}")
        import traceback

        traceback.print_exc()
        return False


async def test_llm_service():
    """Testa o LLM Service com Maritaca"""

    print("\n" + "=" * 60)
    print("üõ†Ô∏è TESTE DO LLM SERVICE")
    print("=" * 60)

    from src.llm.services import LLMService, LLMServiceConfig

    print("\n1. Criando LLM Service com Maritaca...")
    try:
        config = LLMServiceConfig(
            primary_provider="maritaca",
            enable_fallback=False,
            temperature=0.5,
            max_tokens=200,
        )

        service = LLMService(config)
        print("   ‚úÖ LLM Service criado")
    except Exception as e:
        print(f"   ‚ùå Erro ao criar service: {e}")
        return False

    print("\n2. Testando summarization...")
    try:
        text = """
        O Portal da Transpar√™ncia do Governo Federal √© uma ferramenta que
        permite ao cidad√£o acompanhar como o dinheiro p√∫blico est√° sendo
        utilizado. Por meio dele, √© poss√≠vel consultar informa√ß√µes sobre
        recursos federais transferidos a estados, munic√≠pios e outros.
        """

        summary = await service.summarize(text, max_length=50)
        print("   ‚úÖ Resumo gerado:")
        print(f"   {summary}")

        return True

    except Exception as e:
        print(f"   ‚ùå Erro na summariza√ß√£o: {e}")
        return False


def main():
    """Executa todos os testes"""

    print("\nüöÄ INICIANDO TESTES DE INTEGRA√á√ÉO COM MARITACA AI")
    print("=" * 60)

    # Verificar se API key est√° configurada
    if not os.environ.get("MARITACA_API_KEY"):
        print("\n‚ö†Ô∏è  ATEN√á√ÉO: MARITACA_API_KEY n√£o encontrada!")
        print("\nPara configurar:")
        print("1. Obtenha uma API key em: https://chat.maritaca.ai")
        print("2. Configure no .env: MARITACA_API_KEY=sk-xxxxx")
        print("3. Ou defina aqui no script na linha 19")
        print("\n" + "=" * 60)

        # Em ambiente n√£o-interativo, continuar mesmo assim
        if not sys.stdin.isatty():
            print("\n‚ö†Ô∏è  Executando em modo n√£o-interativo - continuando sem API key")
        else:
            resposta = input("\nDeseja continuar mesmo assim? (s/n): ")
            if resposta.lower() != "s":
                return

    # Executar testes
    asyncio.run(run_tests())

    print("\n" + "=" * 60)
    print("üìä RESUMO")
    print("=" * 60)
    print(
        """
Se todos os testes passaram:
‚úÖ Maritaca AI est√° configurado corretamente!

Para usar em produ√ß√£o (Railway):
1. Configure no Railway Dashboard:
   - LLM_PROVIDER=maritaca
   - MARITACA_API_KEY=sk-xxxxx
   - LLM_MODEL_NAME=sabiazinho-3

2. Reinicie o servi√ßo no Railway

3. Teste uma investiga√ß√£o:
   curl -X POST https://cidadao-api-production.up.railway.app/api/v1/investigations/start \\
     -H "Content-Type: application/json" \\
     -d '{"query":"Teste Maritaca","data_source":"contracts","filters":{},"anomaly_types":["price"]}'
"""
    )


async def run_tests():
    """Executa os testes assincronamente"""

    results = {}

    # Teste 1: Provider b√°sico
    print("\n" + "-" * 60)
    print("TESTE 1: Provider Maritaca")
    print("-" * 60)
    results["provider"] = await test_maritaca_provider()

    # Teste 2: LLM Service
    if results["provider"]:
        print("\n" + "-" * 60)
        print("TESTE 2: LLM Service")
        print("-" * 60)
        results["service"] = await test_llm_service()

    # Teste 3: Investiga√ß√£o (mais demorado)
    if results.get("provider"):
        print("\n" + "-" * 60)
        print("TESTE 3: Investiga√ß√£o com Agente")
        print("-" * 60)
        results["investigation"] = await test_investigation_with_maritaca()

    # Resumo dos resultados
    print("\n" + "=" * 60)
    print("üéØ RESULTADOS DOS TESTES")
    print("=" * 60)

    for test_name, passed in results.items():
        status = "‚úÖ PASSOU" if passed else "‚ùå FALHOU"
        print(f"   {test_name.upper()}: {status}")

    all_passed = all(results.values())

    if all_passed:
        print("\n‚úÖ TODOS OS TESTES PASSARAM!")
        print("   Maritaca AI est√° funcionando corretamente")
    else:
        print("\n‚ùå ALGUNS TESTES FALHARAM")
        print("   Verifique a configura√ß√£o e tente novamente")

    return all_passed


if __name__ == "__main__":
    main()
