# Roadmap de Melhorias - Cidad√£o.AI Backend
**Data**: 20 de Outubro de 2025, 17:15
**An√°lise por**: Anderson Henrique da Silva
**Status do Projeto**: Produ√ß√£o (Railway) - 99.9% uptime

---

## üìä Estado Atual Verificado

### M√©tricas Reais (An√°lise Completa 20/10/2025)
| M√©trica | Valor Atual | Meta | Gap |
|---------|-------------|------|-----|
| **Agentes Tier 1** | 10/16 (63%) | 16/16 (100%) | -6 agentes |
| **Cobertura de Testes** | ~40% | 80% | **-40pp** üî¥ |
| **Agentes Testados** | 12/16 (75%) | 16/16 (100%) | -4 agentes |
| **Uptime Produ√ß√£o** | 99.9% | 99.9% | ‚úÖ Meta atingida |
| **APIs Funcionando** | 266+ endpoints | - | ‚úÖ Completo |
| **Documenta√ß√£o** | 100% agentes | 100% | ‚úÖ Excelente |

### Descobertas Cr√≠ticas

#### üéØ Pontos Fortes
1. **Produ√ß√£o Est√°vel** - Railway com 99.9% uptime desde 07/10/2025
2. **10 Agentes Operacionais** - Tier 1 com implementa√ß√£o s√≥lida
3. **API Robusta** - 266+ endpoints com SSE, autentica√ß√£o, rate limiting
4. **Infraestrutura Completa** - PostgreSQL, Redis, Celery, Prometheus configurados
5. **Documenta√ß√£o Honesta** - IMPLEMENTATION_REALITY.md reconhece gaps

#### ‚ö†Ô∏è Gaps Cr√≠ticos Identificados
1. **Ox√≥ssi sem testes** - 1,698 LOC de detec√ß√£o de fraude, **ZERO arquivos de teste**
2. **Cobertura real 40%** - Documenta√ß√£o afirma 80%, realidade √© 40% (gap de 40pp)
3. **5 agentes Tier 2 incompletos** - 50-70% implementados, frameworks prontos
4. **Dados simulados** - V√°rios agentes usam `asyncio.sleep()` + valores aleat√≥rios
5. **Modelos ML ausentes** - C√©uci tem framework detalhado mas sem modelos treinados
6. **Instrumenta√ß√£o pendente** - Prometheus configurado, c√≥digo Python n√£o instrumentado

---

## üî• PRIORIDADE 1: Semana Atual (21-27 Out 2025)

### 1.1 üß™ Criar Suite de Testes para Ox√≥ssi
**Impacto**: CR√çTICO | **Esfor√ßo**: 8-12 horas | **Status**: üî¥ Bloqueante

**Problema**: Ox√≥ssi implementa 7 padr√µes de fraude (licita√ß√£o direcionada, fornecedores fantasma, carteliza√ß√£o, etc.) mas est√° completamente sem testes.

**A√ß√£o**:
```bash
# Criar arquivo de teste completo
touch tests/unit/agents/test_oxossi.py

# Template m√≠nimo necess√°rio
pytest tests/unit/agents/test_oxossi.py -v --cov=src.agents.oxossi --cov-report=html
```

**Checklist de Testes Essenciais**:
- [ ] `test_detect_bid_rigging()` - Padr√£o de licita√ß√£o direcionada
- [ ] `test_identify_phantom_vendors()` - Fornecedores fantasma
- [ ] `test_price_fixing_detection()` - Carteliza√ß√£o de pre√ßos
- [ ] `test_invoice_fraud_patterns()` - Fraude em notas fiscais
- [ ] `test_conflict_of_interest()` - Conflito de interesses
- [ ] `test_shell_company_detection()` - Empresas de fachada
- [ ] `test_payment_splitting()` - Fracionamento de pagamentos
- [ ] `test_integration_with_zumbi()` - Integra√ß√£o com anomalias
- [ ] `test_edge_cases()` - Casos extremos e valida√ß√£o

**Resultado Esperado**: Cobertura de Ox√≥ssi de 0% ‚Üí 75%+

---

### 1.2 üìè Medir Cobertura Real e Documentar Gaps
**Impacto**: ALTO | **Esfor√ßo**: 2-4 horas | **Status**: üü° Importante

**Problema**: Documenta√ß√£o afirma 80% de cobertura, realidade √© ~40%. Gap de transpar√™ncia.

**A√ß√£o**:
```bash
# Executar relat√≥rio completo
JWT_SECRET_KEY=test SECRET_KEY=test pytest --cov=src --cov-report=html --cov-report=term

# Gerar badge de cobertura
pip install coverage-badge
coverage-badge -o docs/badges/coverage.svg
```

**Entreg√°veis**:
1. **Relat√≥rio HTML** em `htmlcov/index.html` com drill-down por m√≥dulo
2. **Badge de cobertura** em `docs/badges/coverage.svg`
3. **Documento de gaps** listando:
   - M√≥dulos com <60% cobertura
   - Fun√ß√µes cr√≠ticas sem testes
   - Prioriza√ß√£o por impacto

**Atualizar**:
- `README.md` - Badge real de cobertura
- `CLAUDE.md` - M√©tricas honestas
- `docs/project/CURRENT_STATUS_2025_10.md` - N√∫meros verificados

---

### 1.3 üîç Instrumentar M√©tricas Prometheus no C√≥digo
**Impacto**: ALTO | **Esfor√ßo**: 6-8 horas | **Status**: üü° Infraestrutura pronta

**Problema**: Grafana e Prometheus configurados, mas c√≥digo Python n√£o exp√µe m√©tricas.

**A√ß√£o**:
```bash
# Adicionar prometheus_client
echo "prometheus_client==0.19.0" >> requirements.txt
make install-dev
```

**Implementa√ß√£o**:

1. **M√©tricas de Agentes** (`src/agents/metrics_wrapper.py`):
```python
from prometheus_client import Counter, Histogram, Gauge

# Contadores
agent_invocations = Counter('agent_invocations_total', 'Total agent calls', ['agent_id'])
agent_errors = Counter('agent_errors_total', 'Agent errors', ['agent_id', 'error_type'])

# Histogramas (lat√™ncia)
agent_duration = Histogram('agent_duration_seconds', 'Agent processing time', ['agent_id'])

# Gauges (estado atual)
active_investigations = Gauge('active_investigations', 'Current investigations running')
```

2. **M√©tricas de API** (`src/api/middleware/metrics_middleware.py`):
```python
from prometheus_client import Counter, Histogram

http_requests = Counter('http_requests_total', 'HTTP requests', ['method', 'endpoint', 'status'])
http_duration = Histogram('http_duration_seconds', 'HTTP request duration', ['method', 'endpoint'])
```

3. **Endpoint de M√©tricas** (`src/api/routes/monitoring.py`):
```python
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST

@router.get("/metrics")
async def metrics():
    return Response(content=generate_latest(), media_type=CONTENT_TYPE_LATEST)
```

**Verifica√ß√£o**:
```bash
# Iniciar aplica√ß√£o
make run-dev

# Testar endpoint
curl http://localhost:8000/health/metrics

# Verificar Prometheus
curl http://localhost:9090/api/v1/targets
```

**Dashboards Grafana a Atualizar**:
- `agent_performance.json` - Lat√™ncia e throughput por agente
- `api_metrics.json` - Requisi√ß√µes HTTP, erros, p95/p99
- `investigation_metrics.json` - Investiga√ß√µes ativas, taxa de conclus√£o

---

## üìà PRIORIDADE 2: Pr√≥ximas 2 Semanas (28 Out - 10 Nov 2025)

### 2.1 üß™ Expandir Cobertura de Testes: 40% ‚Üí 65%
**Impacto**: ALTO | **Esfor√ßo**: 20-30 horas | **Status**: üü° Planejado

**Estrat√©gia por Prioridade**:

#### Fase 1: Agentes Cr√≠ticos sem Testes (8 horas)
1. **Lampi√£o** (1,587 LOC) - An√°lise regional
   - Criar `tests/unit/agents/test_lampiao.py`
   - Testar Gini, Theil, Williamson indices
   - Validar an√°lise de 27 estados brasileiros

2. **Oscar Niemeyer** (1,228 LOC) - Visualiza√ß√£o
   - Expandir `tests/unit/agents/test_oscar_niemeyer.py`
   - Testar gera√ß√£o Plotly, NetworkX, mapas geogr√°ficos
   - Validar layouts de dashboard

#### Fase 2: Agentes com Testes Insuficientes (12 horas)
3. **Maria Quit√©ria** (2,589 LOC) - Seguran√ßa
   - Expandir teste √∫nico para cobertura completa
   - Testar MITRE ATT&CK, UEBA, compliance LGPD
   - Validar relat√≥rios de auditoria

4. **C√©uci** (1,697 LOC) - ML/Predictivo
   - Criar testes para framework (mesmo sem modelos)
   - Mockar predi√ß√µes ARIMA, LSTM, Prophet
   - Validar API de infer√™ncia

5. **Obaluai√™** (829 LOC) - Corrup√ß√£o
   - Criar suite completa de testes
   - Implementar Benford's Law tests
   - Validar detec√ß√£o de padr√µes suspeitos

#### Fase 3: Servi√ßos Cr√≠ticos (10 horas)
6. **Orchestration System** (`src/services/orchestration/`)
   - Expandir testes de integra√ß√£o
   - Testar intent classification, entity extraction
   - Validar data federation com circuit breakers

7. **Cache Service** (`src/services/cache_service.py`)
   - Testar estrat√©gia multi-layer (memory ‚Üí Redis ‚Üí DB)
   - Validar TTL e invalida√ß√£o
   - Testar failover autom√°tico

**Meta**: 40% ‚Üí 65% cobertura (+25pp)

---

### 2.2 üîÑ Remover Dados Simulados dos Agentes Tier 2
**Impacto**: M√âDIO | **Esfor√ßo**: 15-20 horas | **Status**: üü° T√©cnico

**Problema**: V√°rios agentes usam `asyncio.sleep()` + valores aleat√≥rios em vez de an√°lises reais.

**Agentes a Refatorar**:

#### 1. **Dandara** (788 LOC) - Social Justice
**Localiza√ß√µes**:
- `src/agents/dandara.py:450-470` - C√°lculo Gini simulado
- `src/agents/dandara.py:520-540` - Integra√ß√£o IBGE/DataSUS fake

**Refatora√ß√£o**:
```python
# ANTES (simulado)
async def calculate_gini(self, data):
    await asyncio.sleep(2)  # Fake processing
    return random.uniform(0.4, 0.6)  # Random Gini

# DEPOIS (real)
async def calculate_gini(self, data):
    sorted_data = sorted(data)
    n = len(sorted_data)
    cumsum = np.cumsum(sorted_data)
    return (2 * sum((i+1) * val for i, val in enumerate(sorted_data))) / (n * cumsum[-1]) - (n+1)/n
```

#### 2. **Obaluai√™** (829 LOC) - Corruption Detection
**Localiza√ß√µes**:
- `src/agents/obaluaie.py:350-380` - Benford's Law n√£o implementada
- `src/agents/obaluaie.py:420-450` - An√°lise de padr√µes simulada

**Implementar**:
```python
async def benfords_law_analysis(self, amounts: List[float]) -> Dict:
    """Implementar teste real de Benford's Law."""
    first_digits = [int(str(abs(a))[0]) for a in amounts if a > 0]
    observed = Counter(first_digits)

    # Expected distribution (Benford)
    expected = {d: math.log10(1 + 1/d) for d in range(1, 10)}

    # Chi-square test
    chi_square = sum((observed[d] - expected[d] * len(first_digits))**2 /
                     (expected[d] * len(first_digits)) for d in range(1, 10))

    return {
        "chi_square": chi_square,
        "p_value": 1 - stats.chi2.cdf(chi_square, 8),
        "suspicious": chi_square > 15.507  # p=0.05, df=8
    }
```

#### 3. **Nan√£** (963 LOC) - Memory System
**Problema**: Usa mem√≥ria in-memory, ignora PostgreSQL/Redis

**Refatora√ß√£o**:
- Integrar `SQLAlchemy` para mem√≥ria epis√≥dica persistente
- Usar `Redis` para cache de contexto conversacional
- Implementar pattern learning com hist√≥rico real

**Esfor√ßo estimado**: 6-8 horas por agente = 18-24 horas total

---

### 2.3 üéì Treinar e Integrar Modelos ML para C√©uci
**Impacto**: M√âDIO | **Esfor√ßo**: 30-40 horas | **Status**: üü† Projeto maior

**Problema**: C√©uci tem documenta√ß√£o excelente (1,697 LOC) mas 0% de implementa√ß√£o real.

**Plano de Implementa√ß√£o**:

#### Fase 1: Datasets e Prepara√ß√£o (8 horas)
1. **Coletar dados hist√≥ricos**:
   - Portal da Transpar√™ncia (√∫ltimos 5 anos)
   - PNCP (contratos p√∫blicos 2020-2025)
   - TCE-MG (licita√ß√µes estaduais)

2. **Feature engineering**:
   - S√©ries temporais de valores contratuais
   - Features de sazonalidade (m√™s, trimestre)
   - Lag features (valores passados)
   - Rolling statistics (m√©dias m√≥veis)

#### Fase 2: Treinamento de Modelos (12 horas)
1. **ARIMA** (Auto-Regressive Integrated Moving Average):
```python
from statsmodels.tsa.arima.model import ARIMA

def train_arima(data, order=(5,1,0)):
    model = ARIMA(data, order=order)
    fitted = model.fit()
    return fitted
```

2. **Prophet** (Facebook Time Series):
```python
from prophet import Prophet

def train_prophet(df):
    model = Prophet(
        yearly_seasonality=True,
        weekly_seasonality=False,
        changepoint_prior_scale=0.05
    )
    model.fit(df)
    return model
```

3. **LSTM** (Deep Learning):
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

def train_lstm(X, y):
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, y, epochs=50, batch_size=32)
    return model
```

#### Fase 3: Deploy e Integra√ß√£o (10 horas)
1. **Salvar modelos treinados**:
```bash
models/
‚îú‚îÄ‚îÄ arima_contracts_v1.pkl
‚îú‚îÄ‚îÄ prophet_spending_v1.pkl
‚îî‚îÄ‚îÄ lstm_anomalies_v1.h5
```

2. **API de infer√™ncia** (`src/agents/ceuci.py`):
```python
async def predict_next_quarter(self, historical_data):
    """Predi√ß√£o real usando modelos treinados."""
    # Carregar modelo apropriado
    model = self.load_model("arima_contracts_v1.pkl")

    # Fazer predi√ß√£o
    forecast = model.forecast(steps=3)  # 3 meses

    return {
        "predictions": forecast.tolist(),
        "confidence_intervals": model.conf_int().tolist(),
        "model": "ARIMA(5,1,0)",
        "trained_on": "2020-2025 contracts data"
    }
```

#### Fase 4: Valida√ß√£o e Testes (8 horas)
- Backtesting com dados de 2024
- Cross-validation temporal
- M√©tricas: MAE, RMSE, MAPE
- Testes de drift detection

**Entreg√°veis**:
- 3 modelos treinados e versionados
- API de predi√ß√£o funcional
- Testes automatizados com >75% cobertura
- Documenta√ß√£o de retreinamento

---

## üöÄ PRIORIDADE 3: M√©dio Prazo (Nov-Dez 2025)

### 3.1 üé≠ Completar Agentes Tier 2 (50-70% ‚Üí 95%+)
**Impacto**: ALTO | **Esfor√ßo**: 60-80 horas | **Status**: üü† Estrat√©gico

#### Agente 1: **Abaporu** (Orquestrador Master)
**Status Atual**: 70% - Framework ReAct implementado, coordena√ß√£o usa placeholders

**Melhorias Necess√°rias** (15 horas):
1. **Substituir asyncio.sleep()** por coordena√ß√£o real:
```python
# ANTES
async def coordinate_agents(self, task):
    await asyncio.sleep(2)  # Fake coordination
    return {"status": "delegated"}

# DEPOIS
async def coordinate_agents(self, task):
    # An√°lise real de requisitos
    required_agents = await self._analyze_task_requirements(task)

    # Execu√ß√£o paralela real
    agent_pool = AgentPool()
    tasks = [agent_pool.get_agent(agent_id).process(task)
             for agent_id in required_agents]
    results = await asyncio.gather(*tasks)

    # S√≠ntese de resultados
    return await self._synthesize_results(results)
```

2. **Implementar detec√ß√£o de conflitos**:
   - Validar compatibilidade de agentes
   - Resolver depend√™ncias de execu√ß√£o
   - Implementar retry logic com backoff

3. **Adicionar telemetria de orquestra√ß√£o**:
   - Tempo de coordena√ß√£o
   - Taxas de sucesso por combina√ß√£o de agentes
   - Detec√ß√£o de gargalos

#### Agente 2: **Nan√£** (Sistema de Mem√≥ria)
**Status Atual**: 65% - Estrutura de mem√≥ria definida, sem persist√™ncia

**Melhorias Necess√°rias** (12 horas):
1. **Integrar PostgreSQL para mem√≥ria epis√≥dica**:
```python
class EpisodicMemory:
    async def store_episode(self, episode: Dict):
        async with SessionLocal() as db:
            memory = Memory(
                type="episodic",
                content=episode,
                timestamp=datetime.now(),
                importance_score=self._calculate_importance(episode)
            )
            db.add(memory)
            await db.commit()
```

2. **Usar Redis para cache de contexto**:
```python
class ConversationalMemory:
    async def get_context(self, user_id: str, window: int = 10):
        cache_key = f"context:{user_id}"
        cached = await redis.get(cache_key)
        if cached:
            return json.loads(cached)

        # Buscar do banco
        context = await self._fetch_from_db(user_id, window)
        await redis.setex(cache_key, 300, json.dumps(context))
        return context
```

3. **Implementar pattern learning**:
   - Extrair padr√µes de investiga√ß√µes anteriores
   - Recomendar estrat√©gias baseadas em hist√≥rico
   - Detec√ß√£o de investiga√ß√µes similares

#### Agente 3: **Drummond** (Comunica√ß√£o NLG)
**Status Atual**: 25% - Templates prontos, sem integra√ß√£o LLM

**Melhorias Necess√°rias** (18 horas):
1. **Integrar Maritaca/Claude para gera√ß√£o**:
```python
async def generate_narrative(self, data: Dict, style: str = "formal"):
    prompt = self._build_prompt(data, style)

    # Usar Maritaca (sabiazinho-3) para portugu√™s natural
    response = await self.llm_client.generate(
        model="sabiazinho-3",
        prompt=prompt,
        temperature=0.7,
        max_tokens=1000
    )

    return response
```

2. **Implementar multicanal real**:
   - Email via SendGrid/AWS SES
   - Slack via Webhook
   - Discord via Bot API
   - WhatsApp via Twilio

3. **Sistema de templates din√¢micos**:
   - Templates Jinja2 com dados reais
   - Suporte a markdown, HTML, plain text
   - Personaliza√ß√£o por stakeholder

#### Agente 4: **Obaluai√™** (Detec√ß√£o de Corrup√ß√£o)
**Status Atual**: 15% - Framework criado, algoritmos n√£o implementados

**Melhorias Necess√°rias** (10 horas):
1. **Implementar Benford's Law** (j√° descrito na se√ß√£o 2.2)
2. **Detec√ß√£o de padr√µes de corrup√ß√£o**:
   - Round-tripping (movimenta√ß√µes circulares)
   - Bid splitting (fracionamento de licita√ß√µes)
   - Favoritism detection (favoritismo recorrente)
   - Ghost employees (funcion√°rios fantasma)

3. **Integra√ß√£o com Ox√≥ssi e Zumbi**:
   - Pipeline: Zumbi (anomalias) ‚Üí Obaluai√™ (corrup√ß√£o) ‚Üí Ox√≥ssi (fraude)
   - Score agregado de suspei√ß√£o
   - Prioriza√ß√£o de investiga√ß√µes

**Total Estimado**: 60-80 horas para 5 agentes Tier 2

---

### 3.2 üîê Fortalecer Seguran√ßa e Compliance
**Impacto**: ALTO | **Esfor√ßo**: 25-30 horas | **Status**: üü† Regulat√≥rio

**Motiva√ß√£o**: Sistema lida com dados p√∫blicos sens√≠veis, precisa compliance LGPD/ISO27001.

#### Melhorias Necess√°rias:

1. **Auditoria de Seguran√ßa Completa** (8 horas):
   - Scan de depend√™ncias: `pip-audit`, `safety check`
   - An√°lise est√°tica: `bandit`, `semgrep`
   - Secrets detection: `truffleHog`, `gitleaks`
   - Container scanning: `trivy` para imagens Docker

2. **LGPD Compliance** (10 horas):
   - Implementar data retention policies (90 dias investiga√ß√µes)
   - Anonimiza√ß√£o de CPF/CNPJ em logs
   - Direito ao esquecimento (API de dele√ß√£o)
   - Consent management para dados pessoais
   - Data breach notification system

3. **Hardening de Infraestrutura** (7 horas):
   - Rate limiting por IP mais agressivo (10 req/min ‚Üí 5 req/min)
   - Implementar IP reputation check (AbuseIPDB)
   - WAF rules para SQL injection, XSS
   - TLS 1.3 enforcement
   - Security headers (CSP, HSTS, X-Frame-Options)

4. **Logging e Forensics** (5 horas):
   - Structured logging com ELK stack
   - Audit trail completo (quem, quando, o qu√™)
   - Tamper-proof logs (hash chain)
   - SIEM integration readiness

**Entreg√°veis**:
- Relat√≥rio de auditoria de seguran√ßa
- Certificado de compliance LGPD
- Security.md com responsible disclosure
- Runbook de incident response

---

### 3.3 üìä Expandir Integra√ß√£o com APIs Estaduais
**Impacto**: M√âDIO | **Esfor√ßo**: 40-50 horas | **Status**: üü° Expans√£o

**Motiva√ß√£o**: Portal da Transpar√™ncia tem 78% de endpoints bloqueados (403). Ampliar fontes.

#### Expans√£o de TCEs (Tribunais de Contas Estaduais):

**Atual**: 6 TCEs implementados (SP, RJ, MG, BA, PE, CE)
**Meta**: +8 TCEs (RS, PR, SC, GO, DF, MA, PA, AM)

**Template de Implementa√ß√£o** (5 horas por TCE):
```python
# src/services/transparency_apis/tce_apis/tce_rs_client.py
class TCERSClient:
    """Cliente para TCE-RS (Rio Grande do Sul)."""

    BASE_URL = "https://portaltransparencia.tce.rs.gov.br/api/v1"

    async def get_contracts(self, year: int, entity_id: str):
        """Buscar contratos do TCE-RS."""
        endpoint = f"{self.BASE_URL}/contratos"
        params = {"ano": year, "orgao": entity_id}

        async with httpx.AsyncClient() as client:
            response = await client.get(endpoint, params=params)
            return response.json()
```

#### Novos Endpoints a Implementar:
1. **SICONV** (Conv√™nios Federais) - 8 horas
2. **e-Sic** (Transpar√™ncia Ativa) - 6 horas
3. **CEIS** (Empresas Inid√¥neas) - 4 horas
4. **CNEP** (Entidades Punidas) - 4 horas
5. **CEPIM** (Impedidos de Contratar) - 4 horas

**Total**: 40-50 horas para 8 TCEs + 5 novos endpoints

---

## üí° PRIORIDADE 4: Longo Prazo (2026 Q1)

### 4.1 üé® Frontend Web Completo
**Impacto**: MUITO ALTO | **Esfor√ßo**: 200+ horas | **Status**: üü£ Novo Projeto

**Motiva√ß√£o**: Backend robusto, mas sem interface gr√°fica para usu√°rios finais.

**Proposta**: Desenvolver em `cidadao.ai-frontend/` (Next.js 15)

**Features Essenciais**:
1. **Dashboard Executivo**:
   - Cards de m√©tricas agregadas
   - Gr√°ficos interativos (Plotly.js)
   - Mapa de calor de corrup√ß√£o por estado
   - Timeline de investiga√ß√µes

2. **Chat Interface**:
   - Chat com agentes em tempo real (SSE)
   - Hist√≥rico de conversas
   - Sugest√µes de perguntas
   - Export de conversas (PDF, JSON)

3. **Sistema de Investiga√ß√µes**:
   - Criar investiga√ß√£o via formul√°rio
   - Monitorar progresso em tempo real
   - Visualizar resultados por agente
   - Download de relat√≥rios completos

4. **Painel de Administra√ß√£o**:
   - Gerenciar usu√°rios e permiss√µes
   - Configurar alertas
   - Visualizar m√©tricas de sistema
   - Logs de auditoria

**Stack T√©cnico**:
- Next.js 15 (App Router)
- TypeScript
- TailwindCSS + shadcn/ui
- Zustand (state management)
- React Query (data fetching)
- PWA (service worker + offline)

**Refer√™ncia**: `docs/frontend/` j√° tem documenta√ß√£o inicial

---

### 4.2 ü§ñ Sistema de Auto-Investiga√ß√£o Proativa
**Impacto**: ALTO | **Esfor√ßo**: 60-80 horas | **Status**: üü£ Inovador

**Conceito**: Sistema que monitora APIs 24/7 e inicia investiga√ß√µes automaticamente quando detecta anomalias.

**Arquitetura**:
```
Celery Beat (scheduler) ‚Üí Celery Worker ‚Üí Fetch APIs ‚Üí Zumbi (detect) ‚Üí Auto-Investigation
                                                              ‚Üì
                                                       Alert System ‚Üí Email/Slack/Discord
```

**Implementa√ß√£o**:

1. **Celery Tasks** (j√° existe infraestrutura):
```python
# src/infrastructure/queue/tasks/auto_investigation_tasks.py
@celery_app.task(name="monitor_contracts")
def monitor_contracts():
    """Monitorar contratos em tempo real."""
    # Fetch √∫ltimos contratos (√∫ltimas 24h)
    contracts = fetch_recent_contracts()

    # Detectar anomalias com Zumbi
    anomalies = zumbi.detect_anomalies(contracts)

    if anomalies["high_risk"]:
        # Iniciar investiga√ß√£o autom√°tica
        investigation_id = create_investigation(
            target=anomalies["suspect_contracts"],
            triggered_by="auto_monitor",
            priority="high"
        )

        # Alertar stakeholders
        send_alert(investigation_id, anomalies)
```

2. **Configurar Schedules**:
```python
# config/celery_config.py
CELERYBEAT_SCHEDULE = {
    'monitor-contracts-daily': {
        'task': 'monitor_contracts',
        'schedule': crontab(hour=6, minute=0),  # 6am daily
    },
    'check-pncp-hourly': {
        'task': 'check_pncp_updates',
        'schedule': crontab(minute=0),  # Every hour
    },
}
```

3. **Sistema de Alertas**:
   - Email para gestores p√∫blicos
   - Slack para equipe t√©cnica
   - Discord para comunidade
   - Telegram para jornalistas cadastrados

**Benef√≠cio**: Detec√ß√£o proativa de fraudes sem interven√ß√£o humana.

---

### 4.3 üì± API P√∫blica e SDK para Desenvolvedores
**Impacto**: M√âDIO | **Esfor√ßo**: 40-50 horas | **Status**: üü£ Ecossistema

**Motiva√ß√£o**: Permitir que terceiros (jornalistas, ONGs, pesquisadores) integrem Cidad√£o.AI.

**Componentes**:

1. **API Key System**:
```python
# src/models/api_key.py
class APIKey(Base):
    __tablename__ = "api_keys"

    id = Column(UUID, primary_key=True)
    user_id = Column(UUID, ForeignKey("users.id"))
    key = Column(String, unique=True)
    name = Column(String)  # "Jornal O Globo - Investiga√ß√£o"
    tier = Column(String)  # "free", "basic", "premium"
    rate_limit = Column(Integer)  # requests/hour
    expires_at = Column(DateTime)
```

2. **SDK Python**:
```python
# cidadao-ai-sdk/
from cidadao_ai import CidadaoAI

client = CidadaoAI(api_key="ca_xxxxxxxxxxxx")

# Investigar empresa
investigation = client.investigations.create(
    target_cnpj="00.000.000/0001-00",
    agents=["zumbi", "oxossi", "obaluaie"]
)

# Aguardar resultado
result = investigation.wait()
print(result.summary)
```

3. **SDK JavaScript/TypeScript**:
```typescript
import { CidadaoAI } from '@cidadao-ai/sdk';

const client = new CidadaoAI({ apiKey: process.env.CIDADAO_API_KEY });

const investigation = await client.investigations.create({
  targetCnpj: '00.000.000/0001-00',
  agents: ['zumbi', 'oxossi'],
});

console.log(investigation.summary);
```

4. **Documenta√ß√£o Interativa**:
   - OpenAPI 3.1 spec completo
   - Swagger UI + Redoc
   - Exemplos em 5 linguagens (Python, JS, Ruby, Go, PHP)
   - Rate limits e pricing claramente documentados

**Tiers de Uso**:
| Tier | Requests/Hour | Agents Simult√¢neos | Pre√ßo |
|------|---------------|-------------------|-------|
| Free | 10 | 2 | R$ 0 |
| Basic | 100 | 5 | R$ 99/m√™s |
| Premium | 1000 | 16 | R$ 499/m√™s |
| Enterprise | Ilimitado | Ilimitado | Contato |

---

## üìä Resumo Executivo de Prioridades

### Impacto vs Esfor√ßo (Matriz de Decis√£o)

```
        Alto Impacto
             ‚îÇ
   P2.3 ‚óè    ‚îÇ    ‚óè P3.1     ‚óè P4.1
             ‚îÇ
   P2.2 ‚óè    ‚îÇ    ‚óè P3.2
             ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Esfor√ßo
             ‚îÇ
   P1.1 ‚óè    ‚îÇ    ‚óè P2.1
   P1.2 ‚óè    ‚îÇ
   P1.3 ‚óè    ‚îÇ    ‚óè P4.2
             ‚îÇ    ‚óè P4.3
      Baixo Esfor√ßo
```

### Timeline Sugerido

| Per√≠odo | Foco Principal | Entreg√°veis | Horas |
|---------|----------------|-------------|-------|
| **Semana 1** (21-27 Out) | Testes + M√©tricas | Ox√≥ssi testado, Coverage real, Prometheus | 16-24h |
| **Semanas 2-3** (28 Out-10 Nov) | Qualidade | +25pp coverage, Dados reais, ML b√°sico | 50-70h |
| **Nov-Dez 2025** | Completude | Tier 2 completo, Seguran√ßa, APIs | 125-160h |
| **2026 Q1** | Expans√£o | Frontend, Auto-investiga√ß√£o, SDK | 300+h |

### KPIs para Acompanhar

| M√©trica | Atual | Meta Dez/2025 | Meta Mar/2026 |
|---------|-------|---------------|---------------|
| **Cobertura de Testes** | 40% | 75% | 85% |
| **Agentes Tier 1** | 10/16 (63%) | 15/16 (94%) | 16/16 (100%) |
| **APIs Integradas** | 37 | 50 | 70 |
| **Uptime** | 99.9% | 99.95% | 99.99% |
| **Usu√°rios Ativos** | N/A | 100 | 1000 |
| **Investiga√ß√µes/M√™s** | ~50 | 500 | 5000 |

---

## üéØ Recomenda√ß√£o Imediata para Esta Semana

Anderson, baseado na an√°lise completa, recomendo focar em:

### Segunda-feira (21 Out):
- [ ] Criar `tests/unit/agents/test_oxossi.py` completo (8-12h)
- [ ] Atingir 75%+ de cobertura em Ox√≥ssi

### Ter√ßa-feira (22 Out):
- [ ] Medir cobertura real com `pytest --cov` (2h)
- [ ] Documentar gaps no relat√≥rio HTML (2h)
- [ ] Atualizar badges e documenta√ß√£o (1h)

### Quarta-feira (23 Out):
- [ ] Adicionar `prometheus_client` ao projeto (1h)
- [ ] Instrumentar m√©tricas de agentes (4h)
- [ ] Expor endpoint `/health/metrics` (2h)

### Quinta-feira (24 Out):
- [ ] Instrumentar m√©tricas de API (3h)
- [ ] Configurar dashboards Grafana (3h)
- [ ] Testar stack completo localmente (2h)

### Sexta-feira (25 Out):
- [ ] Deploy das mudan√ßas no Railway (1h)
- [ ] Validar m√©tricas em produ√ß√£o (2h)
- [ ] Documentar pr√≥ximos passos (2h)

**Total estimado**: 16-24 horas de desenvolvimento focado

---

## üìö Refer√™ncias e Recursos

### Documenta√ß√£o Interna
- `docs/project/COMPREHENSIVE_ANALYSIS_2025_10_20.md` - An√°lise completa verificada
- `docs/project/CURRENT_STATUS_2025_10.md` - Status oficial dos agentes
- `docs/project/IMPLEMENTATION_REALITY.md` - Gaps entre docs e c√≥digo
- `docs/agents/INVENTORY.md` - Registro completo de agentes

### Ferramentas Recomendadas
- **Testes**: `pytest`, `pytest-cov`, `pytest-asyncio`, `hypothesis`
- **M√©tricas**: `prometheus_client`, `grafana`, `statsd`
- **Seguran√ßa**: `bandit`, `safety`, `pip-audit`, `semgrep`
- **ML**: `scikit-learn`, `statsmodels`, `prophet`, `tensorflow`
- **Qualidade**: `black`, `ruff`, `mypy`, `isort`

### Benchmarks de Refer√™ncia
- **Test Coverage**: [Google: 80%](https://testing.googleblog.com/), [Mozilla: 70%](https://wiki.mozilla.org/), [Meta: 85%](https://engineering.fb.com/)
- **API Uptime**: [AWS: 99.99%](https://aws.amazon.com/compute/sla/), [GCP: 99.95%](https://cloud.google.com/compute/sla)
- **Response Time**: [p95 <300ms](https://sre.google/), [p99 <1s](https://sre.google/)

---

## ‚úÖ Checklist de A√ß√µes Imediatas

### Para come√ßar hoje (20 Out, 17:15):
- [ ] Revisar este documento completo
- [ ] Decidir prioridades para semana 1
- [ ] Criar branch `feature/week-1-improvements`
- [ ] Preparar ambiente de testes

### Segunda-feira (21 Out):
- [ ] Iniciar implementa√ß√£o de testes para Ox√≥ssi
- [ ] Configurar pytest-cov para relat√≥rios HTML
- [ ] Documentar descobertas no Slack/Discord da equipe

---

**Documento criado em**: 20 de Outubro de 2025, 17:30
**Pr√≥xima revis√£o**: 27 de Outubro de 2025
**Respons√°vel**: Anderson Henrique da Silva
**Status**: üü¢ Aprovado para execu√ß√£o
