# üèóÔ∏è Oscar Niemeyer - Arquiteto de Dados

**Status**: ‚ö†Ô∏è **90% Completo** (Beta - Pronto para uso com limita√ß√µes conhecidas)
**Arquivo**: `src/agents/oscar_niemeyer.py`
**Tamanho**: 22KB
**M√©todos Implementados**: ~15
**Testes**: ‚úÖ Sim (`tests/unit/agents/test_oscar_niemeyer.py`)
**TODOs**: Alguns (visualiza√ß√µes avan√ßadas 3D, WebGL)
**√öltima Atualiza√ß√£o**: 2025-10-03 09:10:00 -03:00

---

## üéØ Miss√£o

Agrega√ß√£o inteligente de dados governamentais e gera√ß√£o de metadados otimizados para visualiza√ß√£o no frontend, transformando dados brutos em insights visuais compreens√≠veis. Especialista em preparar dados para dashboards, gr√°ficos e mapas interativos.

**Inspira√ß√£o Cultural**: Oscar Niemeyer (1907-2012), arquiteto brasileiro modernista, criador de Bras√≠lia e √≠cone do design brasileiro. Conhecido por transformar conceitos abstratos em formas visuais elegantes e funcionais.

---

## üìä Tipos de Agrega√ß√£o Suportados

```python
class AggregationType(Enum):
    SUM = "sum"              # Soma total
    COUNT = "count"          # Contagem
    AVERAGE = "average"      # M√©dia aritm√©tica
    MEDIAN = "median"        # Mediana
    MIN = "min"              # M√≠nimo
    MAX = "max"              # M√°ximo
    PERCENTILE = "percentile"  # Percentis (25, 50, 75, 95, 99)
    STDDEV = "stddev"        # Desvio padr√£o
    VARIANCE = "variance"    # Vari√¢ncia
```

---

## üìà Tipos de Visualiza√ß√£o

```python
class VisualizationType(Enum):
    LINE_CHART = "line_chart"      # Gr√°fico de linhas (s√©ries temporais)
    BAR_CHART = "bar_chart"        # Gr√°fico de barras (compara√ß√µes)
    PIE_CHART = "pie_chart"        # Gr√°fico de pizza (propor√ß√µes)
    SCATTER_PLOT = "scatter_plot"  # Dispers√£o (correla√ß√µes)
    HEATMAP = "heatmap"            # Mapa de calor (matriz 2D)
    TREEMAP = "treemap"            # Treemap (hierarquias)
    SANKEY = "sankey"              # Diagrama Sankey (fluxos)
    GAUGE = "gauge"                # Medidor (KPIs)
    MAP = "map"                    # Mapas geogr√°ficos
    TABLE = "table"                # Tabela de dados
```

**Total**: 10 tipos de visualiza√ß√£o suportados

---

## ‚è±Ô∏è Granularidades Temporais

```python
class TimeGranularity(Enum):
    MINUTE = "minute"    # Minuto a minuto
    HOUR = "hour"        # Por hora
    DAY = "day"          # Di√°rio
    WEEK = "week"        # Semanal
    MONTH = "month"      # Mensal
    QUARTER = "quarter"  # Trimestral
    YEAR = "year"        # Anual
```

---

## üß† Algoritmos e T√©cnicas

### 1. Agrega√ß√£o de Dados Multidimensional

#### ‚úÖ OLAP Cube Operations
```python
# Slice: Selecionar uma fatia espec√≠fica
cube.slice(dimension="state", value="SP")

# Dice: Selecionar sub-cubo
cube.dice(state=["SP", "RJ"], year=[2023, 2024])

# Drill-down: Detalhar (estado ‚Üí munic√≠pio)
cube.drill_down(from_="state", to="municipality")

# Roll-up: Agregar (munic√≠pio ‚Üí estado)
cube.roll_up(from_="municipality", to="state")
```

#### ‚úÖ Pivot Table Generation
- M√∫ltiplas dimens√µes (linhas x colunas)
- Agrega√ß√µes aninhadas
- Grand totals e subtotals

#### ‚úÖ Cross-tabulation
- An√°lise de frequ√™ncia cruzada
- Chi-square para independ√™ncia
- Cram√©r's V para for√ßa de associa√ß√£o

#### ‚úÖ Hierarchical Aggregation
```
Munic√≠pio ‚Üí Microrregi√£o ‚Üí Mesorregi√£o ‚Üí Estado ‚Üí Regi√£o ‚Üí Pa√≠s
```

#### ‚úÖ Window Functions
```sql
-- Moving average (7 dias)
AVG(value) OVER (ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)

-- Cumulative sum
SUM(value) OVER (ORDER BY date)

-- Rank
RANK() OVER (PARTITION BY category ORDER BY value DESC)
```

---

### 2. Otimiza√ß√£o de Dados para Visualiza√ß√£o

#### ‚úÖ Data Sampling
```python
# Para datasets > 10k pontos
if len(data) > 10000:
    # LTTB (Largest Triangle Three Buckets)
    sampled_data = downsample_lttb(data, target_points=1000)
```

#### ‚úÖ Binning Strategies
```python
# Equal-width bins
bins = pd.cut(data, bins=10)

# Equal-frequency bins (quantiles)
bins = pd.qcut(data, q=10)

# Custom bins
bins = [0, 1000, 10000, 100000, float('inf')]
```

#### ‚úÖ Outlier Detection
```python
# IQR method
Q1, Q3 = data.quantile([0.25, 0.75])
IQR = Q3 - Q1
outliers = (data < Q1 - 1.5*IQR) | (data > Q3 + 1.5*IQR)

# Z-score method
z_scores = (data - data.mean()) / data.std()
outliers = np.abs(z_scores) > 3
```

#### ‚úÖ Data Normalization
```python
# Min-Max scaling (0-1)
normalized = (data - data.min()) / (data.max() - data.min())

# Z-score standardization
standardized = (data - data.mean()) / data.std()

# Log transformation
log_data = np.log1p(data)  # log(1 + x)
```

#### ‚úÖ Missing Value Interpolation
```python
# Linear interpolation
data_filled = data.interpolate(method='linear')

# Spline interpolation
data_filled = data.interpolate(method='spline', order=3)

# Forward fill
data_filled = data.ffill()
```

---

### 3. An√°lise de S√©ries Temporais

#### ‚úÖ Time Series Decomposition
```python
# STL (Seasonal-Trend decomposition using Loess)
decomposition = seasonal_decompose(timeseries, model='additive')
trend = decomposition.trend
seasonal = decomposition.seasonal
residual = decomposition.resid
```

#### ‚úÖ Moving Averages
```python
# Simple Moving Average (SMA)
sma = data.rolling(window=7).mean()

# Exponential Moving Average (EMA)
ema = data.ewm(span=7, adjust=False).mean()

# Weighted Moving Average (WMA)
weights = np.arange(1, window+1)
wma = data.rolling(window).apply(lambda x: np.dot(x, weights)/weights.sum())
```

#### ‚úÖ Autocorrelation Analysis
- ACF (Autocorrelation Function)
- PACF (Partial Autocorrelation Function)
- Identifica√ß√£o de lags significativos

#### ‚úÖ Change Point Detection
- CUSUM (Cumulative Sum)
- Bayesian change point detection
- Detec√ß√£o de mudan√ßas abruptas em tend√™ncias

---

### 4. Gera√ß√£o de Metadados Inteligentes

#### ‚úÖ Automatic Axis Range Detection
```python
# Detec√ß√£o inteligente de escala
if data_range < 100:
    tick_interval = 10
elif data_range < 1000:
    tick_interval = 100
else:
    tick_interval = 10 ** int(np.log10(data_range) - 1)
```

#### ‚úÖ Color Palette Suggestions
```python
# Baseado no tipo de dados
if data_type == "diverging":
    palette = "RdYlGn"  # Vermelho-Amarelo-Verde
elif data_type == "sequential":
    palette = "Blues"
elif data_type == "categorical":
    palette = "Set3"
```

#### ‚úÖ Chart Type Recommendations
```python
def recommend_chart(data_characteristics):
    if temporal and continuous:
        return VisualizationType.LINE_CHART
    elif categorical and numerical:
        return VisualizationType.BAR_CHART
    elif proportions:
        return VisualizationType.PIE_CHART
    elif correlation:
        return VisualizationType.SCATTER_PLOT
```

#### ‚úÖ Data Density Analysis
```python
# Decidir visualiza√ß√£o baseado em densidade
data_density = len(data) / (x_range * y_range)

if data_density > 0.5:
    recommended = VisualizationType.HEATMAP
else:
    recommended = VisualizationType.SCATTER_PLOT
```

---

### 5. Agrega√ß√£o Espacial (Geospatial)

#### ‚úÖ Geospatial Clustering
```python
# DBSCAN para pontos geogr√°ficos
from sklearn.cluster import DBSCAN

coords = np.array([[lat, lon] for lat, lon in data])
clustering = DBSCAN(eps=0.01, min_samples=5).fit(coords)
```

#### ‚úÖ Hexbin Aggregation
```python
# Hexagonal binning para mapas
hexbin = plt.hexbin(x=lon, y=lat, C=values, gridsize=50, reduce_C_function=np.mean)
```

#### ‚úÖ Regional Boundary Aggregation
- Agrega√ß√£o por pol√≠gonos (estados, munic√≠pios)
- Spatial join operations
- Choropleth map data preparation

---

## üìã Estrutura de Dados

### DataAggregationResult
```python
@dataclass
class DataAggregationResult:
    aggregation_id: str
    data_type: str
    aggregation_type: AggregationType
    time_granularity: Optional[TimeGranularity]
    dimensions: List[str]  # ex: ['state', 'category']
    metrics: Dict[str, float]  # ex: {'total': 1000, 'avg': 50}
    data_points: List[Dict[str, Any]]
    metadata: Dict[str, Any]
    timestamp: datetime
```

### VisualizationMetadata
```python
@dataclass
class VisualizationMetadata:
    visualization_id: str
    title: str
    subtitle: Optional[str]
    visualization_type: VisualizationType
    x_axis: Dict[str, Any]  # {label, min, max, ticks}
    y_axis: Dict[str, Any]
    series: List[Dict[str, Any]]  # M√∫ltiplas s√©ries de dados
    filters: Dict[str, Any]  # Filtros aplic√°veis
    options: Dict[str, Any]  # Configura√ß√µes do chart
    data_url: str  # URL para buscar dados
    timestamp: datetime
```

### TimeSeriesData
```python
@dataclass
class TimeSeriesData:
    series_id: str
    metric_name: str
    time_points: List[datetime]
    values: List[float]
    aggregation_type: AggregationType
    granularity: TimeGranularity
    metadata: Dict[str, Any]
```

---

## üíª Exemplos de Uso

### Agregar Despesas Mensais por Estado

```python
from src.agents.oscar_niemeyer import OscarNiemeyerAgent, AggregationType, TimeGranularity

# Inicializar agente
oscar = OscarNiemeyerAgent()
await oscar.initialize()

# Dados brutos de despesas
message = AgentMessage(
    content="Agregar despesas mensais por estado",
    data={
        "raw_data": expenses_dataframe,  # DataFrame com colunas: date, state, value
        "aggregation": AggregationType.SUM,
        "dimensions": ["state"],
        "time_dimension": "date",
        "time_granularity": TimeGranularity.MONTH
    }
)

response = await oscar.process(message, context)

# Resultado
print(response.data["aggregated"])
# {
#   "dimensions": ["state"],
#   "time_granularity": "MONTH",
#   "data_points": [
#     {"state": "SP", "month": "2025-01", "total": 50_000_000},
#     {"state": "SP", "month": "2025-02", "total": 48_000_000},
#     {"state": "RJ", "month": "2025-01", "total": 35_000_000},
#     ...
#   ],
#   "metrics": {
#     "total_overall": 1_500_000_000,
#     "avg_per_state": 55_555_555,
#     "max_month": 120_000_000
#   }
# }
```

### Gerar Metadados para Visualiza√ß√£o

```python
message = AgentMessage(
    content="Gerar metadados para gr√°fico de linha de despesas",
    data={
        "aggregated_data": aggregation_result,
        "visualization_type": VisualizationType.LINE_CHART,
        "title": "Evolu√ß√£o de Despesas P√∫blicas por Estado"
    }
)

response = await oscar.process(message, context)

# Metadados prontos para frontend
print(response.data["visualization_metadata"])
# {
#   "visualization_type": "line_chart",
#   "title": "Evolu√ß√£o de Despesas P√∫blicas por Estado",
#   "x_axis": {
#     "label": "M√™s",
#     "type": "datetime",
#     "min": "2025-01-01",
#     "max": "2025-12-31",
#     "format": "%b %Y"
#   },
#   "y_axis": {
#     "label": "Total de Despesas (R$)",
#     "type": "linear",
#     "min": 0,
#     "max": 60_000_000,
#     "format": ",.0f"
#   },
#   "series": [
#     {"name": "SP", "data": [...], "color": "#1f77b4"},
#     {"name": "RJ", "data": [...], "color": "#ff7f0e"},
#     {"name": "MG", "data": [...], "color": "#2ca02c"}
#   ],
#   "options": {
#     "legend": {"position": "top"},
#     "tooltip": {"enabled": True},
#     "responsive": True
#   }
# }
```

### Otimizar Dados para Mapa de Calor

```python
message = AgentMessage(
    content="Preparar heatmap de contratos por regi√£o",
    data={
        "raw_data": contracts_by_municipality,  # 5570 munic√≠pios
        "visualization_type": VisualizationType.HEATMAP,
        "optimize": True  # Aplicar binning e agrega√ß√£o espacial
    }
)

response = await oscar.process(message, context)

# Dados otimizados
print(response.data["optimized_data"])
# {
#   "grid_size": [50, 50],  # 2500 c√©lulas vs 5570 munic√≠pios
#   "cells": [
#     {"lat_bin": 0, "lon_bin": 0, "value": 150, "count": 23},
#     {"lat_bin": 0, "lon_bin": 1, "value": 230, "count": 45},
#     ...
#   ],
#   "color_scale": {
#     "min": 0,
#     "max": 1000,
#     "palette": "YlOrRd",
#     "bins": [0, 100, 250, 500, 750, 1000]
#   }
# }
```

---

## üß™ Testes

### Cobertura
- ‚úÖ Testes unit√°rios: `tests/unit/agents/test_oscar_niemeyer.py`
- ‚úÖ Testes de integra√ß√£o: Visualiza√ß√£o com dados reais
- ‚úÖ Performance: Agrega√ß√£o de 100k+ registros

### Cen√°rios Testados
1. **Agrega√ß√£o temporal** (dia, semana, m√™s, ano)
2. **Pivot tables** multidimensionais
3. **Data sampling** (LTTB) para grandes datasets
4. **Gera√ß√£o de metadados** para todos tipos de chart
5. **Otimiza√ß√£o espacial** para mapas

---

## ‚ö†Ô∏è Limita√ß√µes Conhecidas

### TODOs Pendentes

1. **Visualiza√ß√µes 3D** (n√£o implementadas)
   - Surface plots, 3D scatter
   - WebGL rendering metadata

2. **Anima√ß√µes** (parcial)
   - Transi√ß√µes temporais
   - Animated transitions metadata

3. **Dashboards Compostos**
   - Layout autom√°tico de m√∫ltiplos charts
   - Responsive grid generation

### Performance

- ‚úÖ Otimizado at√© 100k pontos
- ‚ö†Ô∏è >1M pontos: requer sampling agressivo
- ‚úÖ Caching de agrega√ß√µes frequentes

---

## üîÑ Integra√ß√£o com Outros Agentes

### Consumidores

1. **Tiradentes (Reporter)**
   - Recebe dados agregados
   - Gera relat√≥rios visuais

2. **Lampi√£o (Regional)**
   - Usa agrega√ß√£o geogr√°fica
   - Mapas choropleth

3. **Anita (Analyst)**
   - Consome s√©ries temporais agregadas
   - An√°lise de tend√™ncias

### Sa√≠da para Frontend

- ‚úÖ JSON estruturado otimizado
- ‚úÖ Metadados compat√≠veis com Chart.js, D3.js, Plotly
- ‚úÖ URLs de dados paginados

---

## üìä M√©tricas Prometheus

```python
# Agrega√ß√µes realizadas
oscar_aggregations_total{type="sum", granularity="month"}

# Tempo de processamento
oscar_aggregation_duration_seconds

# Pontos de dados processados
oscar_datapoints_processed_total

# Cache hit rate
oscar_cache_hit_rate
```

---

## üöÄ Roadmap para 100%

### Alta Prioridade

1. **Implementar visualiza√ß√µes 3D** (Surface, 3D scatter)
2. **Adicionar animation metadata** generation
3. **Dashboard layout** autom√°tico

### M√©dia Prioridade

4. **Integra√ß√£o com Superset/Metabase**
5. **Real-time streaming** data aggregation
6. **Custom color palettes** por tema governamental

---

## üìö Refer√™ncias

### Cultural
- **Oscar Niemeyer**: Arquiteto brasileiro (1907-2012)
- **Obras**: Bras√≠lia, Congresso Nacional, Museu de Arte Contempor√¢nea de Niter√≥i

### T√©cnicas
- **OLAP**: Codd et al. (1993)
- **LTTB Downsampling**: Sveinn Steinarsson (2013)
- **STL Decomposition**: Cleveland et al. (1990)

---

## ü§ù Contribuindo

Para completar os 10% restantes:

1. **Implementar 3D visualization** metadata
2. **Adicionar animation** support
3. **Dashboard composer** com layout autom√°tico

---

## ‚úÖ Status de Produ√ß√£o

**Deploy**: ‚ö†Ô∏è Beta - Pronto para visualiza√ß√µes 2D
**Testes**: ‚úÖ 90% dos cen√°rios cobertos
**Performance**: ‚úÖ 100k+ pontos otimizados
**Frontend Ready**: ‚úÖ Metadados compat√≠veis com libs populares

**Aprovado para uso em**:
- ‚úÖ Dashboards 2D (line, bar, pie, scatter, heatmap)
- ‚úÖ Mapas geogr√°ficos (choropleth, hexbin)
- ‚úÖ Tabelas de dados agregados
- ‚ö†Ô∏è Visualiza√ß√µes 3D (em desenvolvimento)

---

**Autor**: Anderson Henrique da Silva
**Manuten√ß√£o**: Ativa
**Vers√£o**: 0.90 (Beta)
**License**: Proprietary
